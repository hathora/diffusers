//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_90a
.address_size 64

	// .globl	triton_
.extern .shared .align 16 .b8 global_smem[];
.global .align 1 .b8 _$_str[11] = {95, 95, 67, 85, 68, 65, 95, 70, 84, 90};

.visible .entry triton_(
	.param .u64 triton__param_0,
	.param .u64 triton__param_1,
	.param .u64 triton__param_2,
	.param .u64 triton__param_3,
	.param .u64 triton__param_4,
	.param .u64 triton__param_5,
	.param .u64 triton__param_6,
	.param .u64 triton__param_7,
	.param .u64 triton__param_8,
	.param .u64 triton__param_9,
	.param .u32 triton__param_10,
	.param .u32 triton__param_11
)
.maxntid 256, 1, 1
{
	.reg .pred 	%p<136>;
	.reg .b16 	%rs<185>;
	.reg .b32 	%r<225>;
	.reg .f32 	%f<271>;
	.reg .b64 	%rd<89>;
	.loc	1 18 0
$L__func_begin0:
	.loc	1 18 0

	ld.param.u64 	%rd61, [triton__param_0];
	ld.param.u64 	%rd62, [triton__param_1];
$L__tmp0:
	.loc	1 20 28
	// begin inline asm
	mov.u32 %r1, %ctaid.x;
	// end inline asm
	.loc	1 20 33
	shl.b32 	%r148, %r1, 3;
	ld.param.u64 	%rd63, [triton__param_2];
	ld.param.u64 	%rd64, [triton__param_3];
	.loc	1 21 44
	mov.u32 	%r149, %tid.x;
	ld.param.u64 	%rd65, [triton__param_4];
	bfe.u32 	%r150, %r149, 5, 3;
	ld.param.u64 	%rd66, [triton__param_5];
	and.b32  	%r151, %r149, 31;
	ld.param.u64 	%rd67, [triton__param_6];
	and.b32  	%r152, %r149, 7;
	ld.param.u64 	%rd68, [triton__param_7];
	.loc	1 21 23
	or.b32  	%r153, %r148, %r150;
	ld.param.u64 	%rd69, [triton__param_8];
	or.b32  	%r154, %r148, %r152;
	ld.param.u64 	%rd70, [triton__param_9];
	ld.param.u32 	%r155, [triton__param_10];
	.loc	1 22 21
	setp.lt.s32 	%p1, %r153, %r155;
	setp.lt.s32 	%p133, %r154, %r155;
	.loc	1 23 33
	and.b32  	%r156, %r149, 8;
	shl.b32 	%r157, %r149, 2;
	and.b32  	%r158, %r157, 124;
	shr.u32 	%r159, %r149, 3;
	.loc	1 50 20
	mul.hi.s32 	%r161, %r153, 715827883;
	shr.u32 	%r162, %r161, 31;
	shr.s32 	%r163, %r161, 2;
	add.s32 	%r164, %r163, %r162;
	mul.lo.s32 	%r165, %r164, 24;
	sub.s32 	%r166, %r153, %r165;
	.loc	1 25 18
	mul.hi.s32 	%r167, %r154, 715827883;
	shr.u32 	%r168, %r167, 31;
	shr.u32 	%r169, %r167, 2;
	add.s32 	%r170, %r169, %r168;
	mul.lo.s32 	%r171, %r170, 24;
	sub.s32 	%r172, %r154, %r171;
	.loc	1 32 44
	shl.b32 	%r173, %r153, 7;
	shl.b32 	%r174, %r154, 7;
	.loc	1 32 40
	or.b32  	%r175, %r173, %r158;
	.loc	1 32 34
	mul.wide.s32 	%rd71, %r175, 2;
	add.s64 	%rd1, %rd63, %rd71;
	mov.b32 	%r4, 0;
	.loc	1 32 50
	// begin inline asm
	mov.u32 %r2, 0x0;
	mov.u32 %r3, 0x0;
	@%p1 ld.global.L1::evict_last.v2.b32 { %r2, %r3 }, [ %rd1 + 0 ];
	@!%p1 mov.u32 %r2, %r4;
	@!%p1 mov.u32 %r3, %r4;
	// end inline asm
	cvt.u16.u32 	%rs1, %r2;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs2}, %r2; }
	cvt.u16.u32 	%rs3, %r3;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs4}, %r3; }
	.loc	1 32 109
	// begin inline asm
	cvt.f32.bf16 %r6, %rs1;
	// end inline asm
	mov.b32 	%f1, %r6;
	// begin inline asm
	cvt.f32.bf16 %r7, %rs2;
	// end inline asm
	mov.b32 	%f2, %r7;
	// begin inline asm
	cvt.f32.bf16 %r8, %rs3;
	// end inline asm
	mov.b32 	%f3, %r8;
	// begin inline asm
	cvt.f32.bf16 %r9, %rs4;
	// end inline asm
	mov.b32 	%f4, %r9;
	.loc	1 33 44
	shl.b32 	%r176, %r166, 7;
	shl.b32 	%r177, %r172, 7;
	.loc	1 33 40
	or.b32  	%r178, %r176, %r158;
	.loc	1 33 34
	mul.wide.s32 	%rd72, %r178, 2;
	add.s64 	%rd2, %rd64, %rd72;
	.loc	1 33 50
	// begin inline asm
	mov.u32 %r10, 0x0;
	mov.u32 %r11, 0x0;
	@%p1 ld.global.L1::evict_last.v2.b32 { %r10, %r11 }, [ %rd2 + 0 ];
	@!%p1 mov.u32 %r10, %r4;
	@!%p1 mov.u32 %r11, %r4;
	// end inline asm
	cvt.u16.u32 	%rs5, %r10;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs6}, %r10; }
	cvt.u16.u32 	%rs7, %r11;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs8}, %r11; }
	.loc	1 33 109
	// begin inline asm
	cvt.f32.bf16 %r14, %rs5;
	// end inline asm
	mov.b32 	%f5, %r14;
	// begin inline asm
	cvt.f32.bf16 %r15, %rs6;
	// end inline asm
	mov.b32 	%f6, %r15;
	// begin inline asm
	cvt.f32.bf16 %r16, %rs7;
	// end inline asm
	mov.b32 	%f7, %r16;
	// begin inline asm
	cvt.f32.bf16 %r17, %rs8;
	// end inline asm
	mov.b32 	%f8, %r17;
	.loc	1 34 34
	add.s64 	%rd3, %rd65, %rd71;
	.loc	1 34 50
	// begin inline asm
	mov.u32 %r18, 0x0;
	mov.u32 %r19, 0x0;
	@%p1 ld.global.L1::evict_last.v2.b32 { %r18, %r19 }, [ %rd3 + 0 ];
	@!%p1 mov.u32 %r18, %r4;
	@!%p1 mov.u32 %r19, %r4;
	// end inline asm
	cvt.u16.u32 	%rs9, %r18;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs10}, %r18; }
	cvt.u16.u32 	%rs11, %r19;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs12}, %r19; }
	.loc	1 34 109
	// begin inline asm
	cvt.f32.bf16 %r22, %rs9;
	// end inline asm
	mov.b32 	%f9, %r22;
	// begin inline asm
	cvt.f32.bf16 %r23, %rs10;
	// end inline asm
	mov.b32 	%f10, %r23;
	// begin inline asm
	cvt.f32.bf16 %r24, %rs11;
	// end inline asm
	mov.b32 	%f11, %r24;
	// begin inline asm
	cvt.f32.bf16 %r25, %rs12;
	// end inline asm
	mov.b32 	%f12, %r25;
	.loc	1 35 34
	add.s64 	%rd4, %rd66, %rd72;
	.loc	1 35 50
	// begin inline asm
	mov.u32 %r26, 0x0;
	mov.u32 %r27, 0x0;
	@%p1 ld.global.L1::evict_last.v2.b32 { %r26, %r27 }, [ %rd4 + 0 ];
	@!%p1 mov.u32 %r26, %r4;
	@!%p1 mov.u32 %r27, %r4;
	// end inline asm
	cvt.u16.u32 	%rs13, %r26;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs14}, %r26; }
	cvt.u16.u32 	%rs15, %r27;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs16}, %r27; }
	.loc	1 35 109
	// begin inline asm
	cvt.f32.bf16 %r30, %rs13;
	// end inline asm
	mov.b32 	%f13, %r30;
	// begin inline asm
	cvt.f32.bf16 %r31, %rs14;
	// end inline asm
	mov.b32 	%f14, %r31;
	// begin inline asm
	cvt.f32.bf16 %r32, %rs15;
	// end inline asm
	mov.b32 	%f15, %r32;
	// begin inline asm
	cvt.f32.bf16 %r33, %rs16;
	// end inline asm
	mov.b32 	%f16, %r33;
	.loc	1 36 22
	add.f32 	%f17, %f1, %f5;
	add.f32 	%f18, %f2, %f6;
	add.f32 	%f19, %f3, %f7;
	add.f32 	%f20, %f4, %f8;
	.loc	1 37 22
	mul.f32 	%f21, %f18, %f18;
	.loc	1 42 23
	add.f32 	%f22, %f9, %f13;
	add.f32 	%f23, %f10, %f14;
	add.f32 	%f24, %f11, %f15;
	add.f32 	%f25, %f12, %f16;
	.loc	1 43 24
	mul.f32 	%f26, %f23, %f23;
$L__tmp1:
	.loc	2 256 15
	fma.rn.f32 	%f27, %f17, %f17, %f21;
	fma.rn.f32 	%f28, %f19, %f19, %f27;
	fma.rn.f32 	%f29, %f20, %f20, %f28;
	selp.f32 	%f30, %f29, 0f00000000, %p1;
	.loc	2 267 36
	mov.b32 	%r179, %f30;
	shfl.sync.bfly.b32	%r180, %r179, 16, 31, -1;
	mov.b32 	%f31, %r180;
	.loc	2 256 15
	add.f32 	%f32, %f30, %f31;
	.loc	2 267 36
	mov.b32 	%r181, %f32;
	shfl.sync.bfly.b32	%r182, %r181, 8, 31, -1;
	mov.b32 	%f33, %r182;
	.loc	2 256 15
	add.f32 	%f34, %f32, %f33;
	.loc	2 267 36
	mov.b32 	%r183, %f34;
	shfl.sync.bfly.b32	%r184, %r183, 4, 31, -1;
	mov.b32 	%f35, %r184;
	.loc	2 256 15
	add.f32 	%f36, %f34, %f35;
	.loc	2 267 36
	mov.b32 	%r185, %f36;
	shfl.sync.bfly.b32	%r186, %r185, 2, 31, -1;
	mov.b32 	%f37, %r186;
	.loc	2 256 15
	add.f32 	%f38, %f36, %f37;
	.loc	2 267 36
	mov.b32 	%r187, %f38;
	shfl.sync.bfly.b32	%r188, %r187, 1, 31, -1;
	mov.b32 	%f39, %r188;
	.loc	2 256 15
	add.f32 	%f40, %f38, %f39;
$L__tmp2:
	.loc	2 256 15
	fma.rn.f32 	%f41, %f22, %f22, %f26;
	fma.rn.f32 	%f42, %f24, %f24, %f41;
	fma.rn.f32 	%f43, %f25, %f25, %f42;
	selp.f32 	%f44, %f43, 0f00000000, %p1;
	.loc	2 267 36
	mov.b32 	%r189, %f44;
	shfl.sync.bfly.b32	%r190, %r189, 16, 31, -1;
	mov.b32 	%f45, %r190;
	.loc	2 256 15
	add.f32 	%f46, %f44, %f45;
	.loc	2 267 36
	mov.b32 	%r191, %f46;
	shfl.sync.bfly.b32	%r192, %r191, 8, 31, -1;
	mov.b32 	%f47, %r192;
	.loc	2 256 15
	add.f32 	%f48, %f46, %f47;
	.loc	2 267 36
	mov.b32 	%r193, %f48;
	shfl.sync.bfly.b32	%r194, %r193, 4, 31, -1;
	mov.b32 	%f49, %r194;
	.loc	2 256 15
	add.f32 	%f50, %f48, %f49;
	.loc	2 267 36
	mov.b32 	%r195, %f50;
	shfl.sync.bfly.b32	%r196, %r195, 2, 31, -1;
	mov.b32 	%f51, %r196;
	.loc	2 256 15
	add.f32 	%f52, %f50, %f51;
	.loc	2 267 36
	mov.b32 	%r197, %f52;
	shfl.sync.bfly.b32	%r198, %r197, 1, 31, -1;
	mov.b32 	%f53, %r198;
	.loc	2 256 15
	add.f32 	%f54, %f52, %f53;
$L__tmp3:
	.loc	1 70 42
	and.b32  	%r199, %r159, 30;
	.loc	1 57 51
	// begin inline asm
	mov.u32 %r34, 0x0;
	mov.u32 %r35, 0x0;
	@%p1 ld.global.L1::evict_first.v2.b32 { %r34, %r35 }, [ %rd1 + 0 ];
	@!%p1 mov.u32 %r34, %r4;
	@!%p1 mov.u32 %r35, %r4;
	// end inline asm
	cvt.u16.u32 	%rs17, %r34;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs18}, %r34; }
	cvt.u16.u32 	%rs19, %r35;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs20}, %r35; }
	.loc	1 57 111
	// begin inline asm
	cvt.f32.bf16 %r38, %rs17;
	// end inline asm
	mov.b32 	%f55, %r38;
	// begin inline asm
	cvt.f32.bf16 %r39, %rs18;
	// end inline asm
	mov.b32 	%f56, %r39;
	// begin inline asm
	cvt.f32.bf16 %r40, %rs19;
	// end inline asm
	mov.b32 	%f57, %r40;
	// begin inline asm
	cvt.f32.bf16 %r41, %rs20;
	// end inline asm
	mov.b32 	%f58, %r41;
	.loc	1 59 35
	mul.wide.u32 	%rd73, %r158, 2;
	add.s64 	%rd6, %rd67, %rd73;
	mov.pred 	%p16, -1;
	.loc	1 59 40
	// begin inline asm
	mov.u32 %r42, 0x0;
	mov.u32 %r43, 0x0;
	@%p16 ld.global.L1::evict_last.v2.b32 { %r42, %r43 }, [ %rd6 + 0 ];
	@!%p16 mov.u32 %r42, %r4;
	@!%p16 mov.u32 %r43, %r4;
	// end inline asm
	cvt.u16.u32 	%rs21, %r42;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs22}, %r42; }
	cvt.u16.u32 	%rs23, %r43;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs24}, %r43; }
	.loc	1 59 91
	// begin inline asm
	cvt.f32.bf16 %r46, %rs21;
	// end inline asm
	mov.b32 	%f59, %r46;
	// begin inline asm
	cvt.f32.bf16 %r47, %rs22;
	// end inline asm
	mov.b32 	%f60, %r47;
	// begin inline asm
	cvt.f32.bf16 %r48, %rs23;
	// end inline asm
	mov.b32 	%f61, %r48;
	// begin inline asm
	cvt.f32.bf16 %r49, %rs24;
	// end inline asm
	mov.b32 	%f62, %r49;
	.loc	1 60 45
	shl.b32 	%r200, %r164, 7;
	.loc	1 60 41
	or.b32  	%r201, %r200, %r158;
	.loc	1 60 35
	mul.wide.s32 	%rd74, %r201, 4;
	add.s64 	%rd7, %rd68, %rd74;
	.loc	1 60 51
	// begin inline asm
	mov.u32 %r50, 0x0;
	mov.u32 %r51, 0x0;
	mov.u32 %r52, 0x0;
	mov.u32 %r53, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r50, %r51, %r52, %r53 }, [ %rd7 + 0 ];
	@!%p1 mov.u32 %r50, %r4;
	@!%p1 mov.u32 %r51, %r4;
	@!%p1 mov.u32 %r52, %r4;
	@!%p1 mov.u32 %r53, %r4;
	// end inline asm
	mov.b32 	%f63, %r50;
	mov.b32 	%f64, %r51;
	mov.b32 	%f65, %r52;
	mov.b32 	%f66, %r53;
	.loc	1 61 35
	add.s64 	%rd8, %rd69, %rd74;
	.loc	1 61 51
	// begin inline asm
	mov.u32 %r58, 0x0;
	mov.u32 %r59, 0x0;
	mov.u32 %r60, 0x0;
	mov.u32 %r61, 0x0;
	@%p1 ld.global.L1::evict_last.v4.b32 { %r58, %r59, %r60, %r61 }, [ %rd8 + 0 ];
	@!%p1 mov.u32 %r58, %r4;
	@!%p1 mov.u32 %r59, %r4;
	@!%p1 mov.u32 %r60, %r4;
	@!%p1 mov.u32 %r61, %r4;
	// end inline asm
	mad.lo.s32 	%r202, %r151, 36, %r150;
	shl.b32 	%r203, %r202, 2;
	mov.u32 	%r204, global_smem;
	add.s32 	%r205, %r204, %r203;
	st.shared.u32 	[%r205], %r58;
	st.shared.u32 	[%r205+36], %r59;
	st.shared.u32 	[%r205+72], %r60;
	st.shared.u32 	[%r205+108], %r61;
	bar.sync 	0;
	bfe.u32 	%r206, %r149, 3, 2;
	shl.b32 	%r207, %r150, 2;
	or.b32  	%r208, %r207, %r206;
	mad.lo.s32 	%r209, %r208, 9, %r152;
	shl.b32 	%r210, %r209, 2;
	add.s32 	%r211, %r204, %r210;
	ld.shared.f32 	%f67, [%r211];
	ld.shared.f32 	%f68, [%r211+1152];
	ld.shared.f32 	%f69, [%r211+2304];
	ld.shared.f32 	%f70, [%r211+3456];
	.loc	1 62 51
	// begin inline asm
	mov.u32 %r66, 0x0;
	mov.u32 %r67, 0x0;
	@%p1 ld.global.L1::evict_first.v2.b32 { %r66, %r67 }, [ %rd3 + 0 ];
	@!%p1 mov.u32 %r66, %r4;
	@!%p1 mov.u32 %r67, %r4;
	// end inline asm
	cvt.u16.u32 	%rs25, %r66;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs26}, %r66; }
	cvt.u16.u32 	%rs27, %r67;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs28}, %r67; }
	.loc	1 62 111
	// begin inline asm
	cvt.f32.bf16 %r70, %rs25;
	// end inline asm
	mov.b32 	%f71, %r70;
	// begin inline asm
	cvt.f32.bf16 %r71, %rs26;
	// end inline asm
	mov.b32 	%f72, %r71;
	// begin inline asm
	cvt.f32.bf16 %r72, %rs27;
	// end inline asm
	mov.b32 	%f73, %r72;
	// begin inline asm
	cvt.f32.bf16 %r73, %rs28;
	// end inline asm
	mov.b32 	%f74, %r73;
	.loc	1 64 35
	add.s64 	%rd10, %rd70, %rd73;
	.loc	1 64 40
	// begin inline asm
	mov.u32 %r74, 0x0;
	mov.u32 %r75, 0x0;
	@%p16 ld.global.L1::evict_last.v2.b32 { %r74, %r75 }, [ %rd10 + 0 ];
	@!%p16 mov.u32 %r74, %r4;
	@!%p16 mov.u32 %r75, %r4;
	// end inline asm
	cvt.u16.u32 	%rs29, %r74;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs30}, %r74; }
	cvt.u16.u32 	%rs31, %r75;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs32}, %r75; }
	.loc	1 64 91
	// begin inline asm
	cvt.f32.bf16 %r78, %rs29;
	// end inline asm
	mov.b32 	%f75, %r78;
	// begin inline asm
	cvt.f32.bf16 %r79, %rs30;
	// end inline asm
	mov.b32 	%f76, %r79;
	// begin inline asm
	cvt.f32.bf16 %r80, %rs31;
	// end inline asm
	mov.b32 	%f77, %r80;
	// begin inline asm
	cvt.f32.bf16 %r81, %rs32;
	// end inline asm
	mov.b32 	%f78, %r81;
	.loc	1 69 24
	setp.eq.s32 	%p134, %r156, 0;
	.loc	1 70 35
	cvt.s64.s32 	%rd75, %r174;
	cvt.u64.u32 	%rd76, %r199;
	or.b64  	%rd77, %rd75, %rd76;
	shl.b64 	%rd78, %rd77, 1;
	add.s64 	%rd79, %rd63, %rd78;
	add.s64 	%rd11, %rd79, 2;
	add.s64 	%rd12, %rd79, 66;
	add.s64 	%rd13, %rd79, 130;
	add.s64 	%rd14, %rd79, 194;
	.loc	1 70 75
	and.pred  	%p35, %p134, %p133;
	mov.u16 	%rs34, 0;
	.loc	1 70 59
	// begin inline asm
	mov.u16 %rs41, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs41 }, [ %rd11 + 0 ];
	@!%p35 mov.u16 %rs41, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs42, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs42 }, [ %rd12 + 0 ];
	@!%p35 mov.u16 %rs42, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs43, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs43 }, [ %rd13 + 0 ];
	@!%p35 mov.u16 %rs43, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs44, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs44 }, [ %rd14 + 0 ];
	@!%p35 mov.u16 %rs44, %rs34;
	// end inline asm
	.loc	1 70 126
	// begin inline asm
	cvt.f32.bf16 %r82, %rs41;
	// end inline asm
	mov.b32 	%f79, %r82;
	// begin inline asm
	cvt.f32.bf16 %r83, %rs42;
	// end inline asm
	mov.b32 	%f80, %r83;
	// begin inline asm
	cvt.f32.bf16 %r84, %rs43;
	// end inline asm
	mov.b32 	%f81, %r84;
	// begin inline asm
	cvt.f32.bf16 %r85, %rs44;
	// end inline asm
	mov.b32 	%f82, %r85;
	.loc	1 71 35
	cvt.s64.s32 	%rd80, %r177;
	or.b64  	%rd81, %rd80, %rd76;
	shl.b64 	%rd82, %rd81, 1;
	add.s64 	%rd83, %rd64, %rd82;
	add.s64 	%rd15, %rd83, 2;
	add.s64 	%rd16, %rd83, 66;
	add.s64 	%rd17, %rd83, 130;
	add.s64 	%rd18, %rd83, 194;
	.loc	1 71 59
	// begin inline asm
	mov.u16 %rs53, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs53 }, [ %rd15 + 0 ];
	@!%p35 mov.u16 %rs53, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs54, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs54 }, [ %rd16 + 0 ];
	@!%p35 mov.u16 %rs54, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs55, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs55 }, [ %rd17 + 0 ];
	@!%p35 mov.u16 %rs55, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs56, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs56 }, [ %rd18 + 0 ];
	@!%p35 mov.u16 %rs56, %rs34;
	// end inline asm
	.loc	1 71 126
	// begin inline asm
	cvt.f32.bf16 %r86, %rs53;
	// end inline asm
	mov.b32 	%f83, %r86;
	// begin inline asm
	cvt.f32.bf16 %r87, %rs54;
	// end inline asm
	mov.b32 	%f84, %r87;
	// begin inline asm
	cvt.f32.bf16 %r88, %rs55;
	// end inline asm
	mov.b32 	%f85, %r88;
	// begin inline asm
	cvt.f32.bf16 %r89, %rs56;
	// end inline asm
	mov.b32 	%f86, %r89;
	.loc	1 74 23
	mov.b32 	%r91, %f40;
	mov.b32 	%r92, 1124073472;
	// begin inline asm
	div.full.f32 %r90, %r91, %r92;
	// end inline asm
	mov.b32 	%f87, %r90;
	.loc	1 77 24
	add.f32 	%f88, %f87, 0f358637BD;
	.loc	1 78 32
	rsqrt.approx.ftz.f32 	%f89, %f88;
	.loc	1 79 24
	bar.sync 	0;
	add.s32 	%r212, %r204, %r207;
	st.shared.f32 	[%r212], %f89;
	bar.sync 	0;
	shl.b32 	%r213, %r152, 2;
	add.s32 	%r214, %r204, %r213;
	ld.shared.f32 	%f90, [%r214];
	.loc	1 80 35
	mul.wide.u32 	%rd84, %r199, 2;
	add.s64 	%rd31, %rd67, %rd84;
	add.s64 	%rd19, %rd31, 2;
	add.s64 	%rd20, %rd31, 66;
	add.s64 	%rd21, %rd31, 130;
	add.s64 	%rd22, %rd31, 194;
	.loc	1 80 83
	// begin inline asm
	mov.u16 %rs65, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs65 }, [ %rd19 + 0 ];
	@!%p35 mov.u16 %rs65, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs66, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs66 }, [ %rd20 + 0 ];
	@!%p35 mov.u16 %rs66, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs67, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs67 }, [ %rd21 + 0 ];
	@!%p35 mov.u16 %rs67, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs68, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs68 }, [ %rd22 + 0 ];
	@!%p35 mov.u16 %rs68, %rs34;
	// end inline asm
	.loc	1 80 150
	// begin inline asm
	cvt.f32.bf16 %r93, %rs65;
	// end inline asm
	mov.b32 	%f91, %r93;
	// begin inline asm
	cvt.f32.bf16 %r94, %rs66;
	// end inline asm
	mov.b32 	%f92, %r94;
	// begin inline asm
	cvt.f32.bf16 %r95, %rs67;
	// end inline asm
	mov.b32 	%f93, %r95;
	// begin inline asm
	cvt.f32.bf16 %r96, %rs68;
	// end inline asm
	mov.b32 	%f94, %r96;
	.loc	1 87 25
	and.b32  	%r215, %r159, 1;
	setp.eq.b32 	%p135, %r215, 1;
	.loc	1 90 45
	or.b32  	%r216, %r174, %r199;
	.loc	1 90 35
	mul.wide.s32 	%rd85, %r216, 2;
	add.s64 	%rd23, %rd63, %rd85;
	add.s64 	%rd24, %rd79, 64;
	add.s64 	%rd25, %rd79, 128;
	add.s64 	%rd26, %rd79, 192;
	.loc	1 90 71
	and.pred  	%p59, %p135, %p133;
	.loc	1 90 55
	// begin inline asm
	mov.u16 %rs77, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs77 }, [ %rd23 + 0 ];
	@!%p59 mov.u16 %rs77, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs78, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs78 }, [ %rd24 + 0 ];
	@!%p59 mov.u16 %rs78, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs79, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs79 }, [ %rd25 + 0 ];
	@!%p59 mov.u16 %rs79, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs80, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs80 }, [ %rd26 + 0 ];
	@!%p59 mov.u16 %rs80, %rs34;
	// end inline asm
	.loc	1 90 122
	// begin inline asm
	cvt.f32.bf16 %r97, %rs77;
	// end inline asm
	mov.b32 	%f95, %r97;
	// begin inline asm
	cvt.f32.bf16 %r98, %rs78;
	// end inline asm
	mov.b32 	%f96, %r98;
	// begin inline asm
	cvt.f32.bf16 %r99, %rs79;
	// end inline asm
	mov.b32 	%f97, %r99;
	// begin inline asm
	cvt.f32.bf16 %r100, %rs80;
	// end inline asm
	mov.b32 	%f98, %r100;
	.loc	1 91 45
	or.b32  	%r217, %r177, %r199;
	.loc	1 91 35
	mul.wide.s32 	%rd86, %r217, 2;
	add.s64 	%rd27, %rd64, %rd86;
	add.s64 	%rd28, %rd83, 64;
	add.s64 	%rd29, %rd83, 128;
	add.s64 	%rd30, %rd83, 192;
	.loc	1 91 55
	// begin inline asm
	mov.u16 %rs89, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs89 }, [ %rd27 + 0 ];
	@!%p59 mov.u16 %rs89, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs90, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs90 }, [ %rd28 + 0 ];
	@!%p59 mov.u16 %rs90, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs91, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs91 }, [ %rd29 + 0 ];
	@!%p59 mov.u16 %rs91, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs92, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs92 }, [ %rd30 + 0 ];
	@!%p59 mov.u16 %rs92, %rs34;
	// end inline asm
	.loc	1 91 122
	// begin inline asm
	cvt.f32.bf16 %r101, %rs89;
	// end inline asm
	mov.b32 	%f99, %r101;
	// begin inline asm
	cvt.f32.bf16 %r102, %rs90;
	// end inline asm
	mov.b32 	%f100, %r102;
	// begin inline asm
	cvt.f32.bf16 %r103, %rs91;
	// end inline asm
	mov.b32 	%f101, %r103;
	// begin inline asm
	cvt.f32.bf16 %r104, %rs92;
	// end inline asm
	mov.b32 	%f102, %r104;
	.loc	1 94 35
	add.s64 	%rd32, %rd31, 64;
	add.s64 	%rd33, %rd31, 128;
	add.s64 	%rd34, %rd31, 192;
	.loc	1 94 77
	// begin inline asm
	mov.u16 %rs101, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs101 }, [ %rd31 + 0 ];
	@!%p59 mov.u16 %rs101, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs102, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs102 }, [ %rd32 + 0 ];
	@!%p59 mov.u16 %rs102, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs103, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs103 }, [ %rd33 + 0 ];
	@!%p59 mov.u16 %rs103, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs104, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs104 }, [ %rd34 + 0 ];
	@!%p59 mov.u16 %rs104, %rs34;
	// end inline asm
	.loc	1 94 144
	// begin inline asm
	cvt.f32.bf16 %r105, %rs101;
	// end inline asm
	mov.b32 	%f103, %r105;
	// begin inline asm
	cvt.f32.bf16 %r106, %rs102;
	// end inline asm
	mov.b32 	%f104, %r106;
	// begin inline asm
	cvt.f32.bf16 %r107, %rs103;
	// end inline asm
	mov.b32 	%f105, %r107;
	// begin inline asm
	cvt.f32.bf16 %r108, %rs104;
	// end inline asm
	mov.b32 	%f106, %r108;
	.loc	1 100 24
	add.f32 	%f107, %f5, %f55;
	add.f32 	%f108, %f6, %f56;
	add.f32 	%f109, %f7, %f57;
	add.f32 	%f110, %f8, %f58;
	.loc	1 101 24
	mul.f32 	%f111, %f107, %f89;
	mul.f32 	%f112, %f108, %f89;
	mul.f32 	%f113, %f109, %f89;
	mul.f32 	%f114, %f110, %f89;
	.loc	1 102 24
	add.f32 	%f115, %f59, 0f00000000;
	add.f32 	%f116, %f60, 0f00000000;
	add.f32 	%f117, %f61, 0f00000000;
	add.f32 	%f118, %f62, 0f00000000;
	.loc	1 103 24
	mul.f32 	%f119, %f115, %f111;
	mul.f32 	%f120, %f116, %f112;
	mul.f32 	%f121, %f117, %f113;
	mul.f32 	%f122, %f118, %f114;
	.loc	1 105 24
	mul.f32 	%f123, %f119, %f63;
	mul.f32 	%f124, %f120, %f64;
	mul.f32 	%f125, %f121, %f65;
	mul.f32 	%f126, %f122, %f66;
	bar.sync 	0;
	st.shared.f32 	[%r205], %f123;
	st.shared.f32 	[%r205+36], %f124;
	st.shared.f32 	[%r205+72], %f125;
	st.shared.f32 	[%r205+108], %f126;
	bar.sync 	0;
	ld.shared.f32 	%f127, [%r211];
	ld.shared.f32 	%f128, [%r211+1152];
	ld.shared.f32 	%f129, [%r211+2304];
	ld.shared.f32 	%f130, [%r211+3456];
	.loc	1 110 35
	add.s64 	%rd87, %rd65, %rd78;
	add.s64 	%rd35, %rd87, 2;
	add.s64 	%rd36, %rd87, 66;
	add.s64 	%rd37, %rd87, 130;
	add.s64 	%rd38, %rd87, 194;
	.loc	1 110 59
	// begin inline asm
	mov.u16 %rs113, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs113 }, [ %rd35 + 0 ];
	@!%p35 mov.u16 %rs113, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs114, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs114 }, [ %rd36 + 0 ];
	@!%p35 mov.u16 %rs114, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs115, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs115 }, [ %rd37 + 0 ];
	@!%p35 mov.u16 %rs115, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs116, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs116 }, [ %rd38 + 0 ];
	@!%p35 mov.u16 %rs116, %rs34;
	// end inline asm
	.loc	1 110 126
	// begin inline asm
	cvt.f32.bf16 %r109, %rs113;
	// end inline asm
	mov.b32 	%f131, %r109;
	// begin inline asm
	cvt.f32.bf16 %r110, %rs114;
	// end inline asm
	mov.b32 	%f132, %r110;
	// begin inline asm
	cvt.f32.bf16 %r111, %rs115;
	// end inline asm
	mov.b32 	%f133, %r111;
	// begin inline asm
	cvt.f32.bf16 %r112, %rs116;
	// end inline asm
	mov.b32 	%f134, %r112;
	.loc	1 111 35
	add.s64 	%rd88, %rd66, %rd82;
	add.s64 	%rd39, %rd88, 2;
	add.s64 	%rd40, %rd88, 66;
	add.s64 	%rd41, %rd88, 130;
	add.s64 	%rd42, %rd88, 194;
	.loc	1 111 59
	// begin inline asm
	mov.u16 %rs125, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs125 }, [ %rd39 + 0 ];
	@!%p35 mov.u16 %rs125, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs126, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs126 }, [ %rd40 + 0 ];
	@!%p35 mov.u16 %rs126, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs127, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs127 }, [ %rd41 + 0 ];
	@!%p35 mov.u16 %rs127, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs128, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs128 }, [ %rd42 + 0 ];
	@!%p35 mov.u16 %rs128, %rs34;
	// end inline asm
	.loc	1 111 126
	// begin inline asm
	cvt.f32.bf16 %r113, %rs125;
	// end inline asm
	mov.b32 	%f135, %r113;
	// begin inline asm
	cvt.f32.bf16 %r114, %rs126;
	// end inline asm
	mov.b32 	%f136, %r114;
	// begin inline asm
	cvt.f32.bf16 %r115, %rs127;
	// end inline asm
	mov.b32 	%f137, %r115;
	// begin inline asm
	cvt.f32.bf16 %r116, %rs128;
	// end inline asm
	mov.b32 	%f138, %r116;
	.loc	1 113 24
	mov.b32 	%r118, %f54;
	// begin inline asm
	div.full.f32 %r117, %r118, %r92;
	// end inline asm
	mov.b32 	%f139, %r117;
	.loc	1 115 24
	add.f32 	%f140, %f139, 0f358637BD;
	.loc	1 116 32
	rsqrt.approx.ftz.f32 	%f141, %f140;
	.loc	1 112 24
	add.f32 	%f142, %f134, %f138;
	add.f32 	%f143, %f133, %f137;
	add.f32 	%f144, %f132, %f136;
	add.f32 	%f145, %f131, %f135;
	.loc	1 72 24
	add.f32 	%f146, %f82, %f86;
	.loc	1 79 24
	mul.f32 	%f147, %f146, %f90;
	.loc	1 82 24
	add.f32 	%f148, %f94, 0f00000000;
	.loc	1 84 17
	neg.f32 	%f149, %f147;
	fma.rn.f32 	%f150, %f149, %f148, 0f00000000;
	.loc	1 92 24
	add.f32 	%f151, %f98, %f102;
	.loc	1 93 24
	mul.f32 	%f152, %f90, %f151;
	.loc	1 95 24
	add.f32 	%f153, %f106, 0f00000000;
	.loc	1 96 24
	mul.f32 	%f154, %f152, %f153;
	.loc	1 0 0
	selp.f32 	%f155, %f150, %f154, %p134;
	.loc	1 108 24
	fma.rn.f32 	%f156, %f70, %f155, %f130;
	.loc	1 72 24
	add.f32 	%f157, %f81, %f85;
	.loc	1 79 24
	mul.f32 	%f158, %f157, %f90;
	.loc	1 82 24
	add.f32 	%f159, %f93, 0f00000000;
	.loc	1 84 17
	neg.f32 	%f160, %f158;
	fma.rn.f32 	%f161, %f160, %f159, 0f00000000;
	.loc	1 92 24
	add.f32 	%f162, %f97, %f101;
	.loc	1 93 24
	mul.f32 	%f163, %f90, %f162;
	.loc	1 95 24
	add.f32 	%f164, %f105, 0f00000000;
	.loc	1 96 24
	mul.f32 	%f165, %f163, %f164;
	.loc	1 0 0
	selp.f32 	%f166, %f161, %f165, %p134;
	.loc	1 108 24
	fma.rn.f32 	%f167, %f69, %f166, %f129;
	.loc	1 72 24
	add.f32 	%f168, %f80, %f84;
	.loc	1 79 24
	mul.f32 	%f169, %f168, %f90;
	.loc	1 82 24
	add.f32 	%f170, %f92, 0f00000000;
	.loc	1 84 17
	neg.f32 	%f171, %f169;
	fma.rn.f32 	%f172, %f171, %f170, 0f00000000;
	.loc	1 92 24
	add.f32 	%f173, %f96, %f100;
	.loc	1 93 24
	mul.f32 	%f174, %f90, %f173;
	.loc	1 95 24
	add.f32 	%f175, %f104, 0f00000000;
	.loc	1 96 24
	mul.f32 	%f176, %f174, %f175;
	.loc	1 0 0
	selp.f32 	%f177, %f172, %f176, %p134;
	.loc	1 108 24
	fma.rn.f32 	%f178, %f68, %f177, %f128;
	.loc	1 72 24
	add.f32 	%f179, %f79, %f83;
	.loc	1 79 24
	mul.f32 	%f180, %f179, %f90;
	.loc	1 82 24
	add.f32 	%f181, %f91, 0f00000000;
	.loc	1 84 17
	neg.f32 	%f182, %f180;
	fma.rn.f32 	%f183, %f182, %f181, 0f00000000;
	.loc	1 92 24
	add.f32 	%f184, %f95, %f99;
	.loc	1 93 24
	mul.f32 	%f185, %f90, %f184;
	.loc	1 95 24
	add.f32 	%f186, %f103, 0f00000000;
	.loc	1 96 24
	mul.f32 	%f187, %f185, %f186;
	.loc	1 0 0
	selp.f32 	%f188, %f183, %f187, %p134;
	.loc	1 108 24
	fma.rn.f32 	%f189, %f67, %f188, %f127;
	.loc	1 61 51
	shl.b32 	%r218, %r151, 2;
	.loc	1 117 24
	bar.sync 	0;
	st.shared.f32 	[%r212], %f141;
	bar.sync 	0;
	ld.shared.f32 	%f190, [%r214];
	mul.f32 	%f191, %f145, %f190;
	mul.f32 	%f192, %f144, %f190;
	mul.f32 	%f193, %f143, %f190;
	mul.f32 	%f194, %f142, %f190;
	.loc	1 118 35
	add.s64 	%rd55, %rd70, %rd84;
	add.s64 	%rd43, %rd55, 2;
	add.s64 	%rd44, %rd55, 66;
	add.s64 	%rd45, %rd55, 130;
	add.s64 	%rd46, %rd55, 194;
	.loc	1 118 83
	// begin inline asm
	mov.u16 %rs137, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs137 }, [ %rd43 + 0 ];
	@!%p35 mov.u16 %rs137, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs138, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs138 }, [ %rd44 + 0 ];
	@!%p35 mov.u16 %rs138, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs139, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs139 }, [ %rd45 + 0 ];
	@!%p35 mov.u16 %rs139, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs140, 0x0;
	@%p35 ld.global.L1::evict_last.b16 { %rs140 }, [ %rd46 + 0 ];
	@!%p35 mov.u16 %rs140, %rs34;
	// end inline asm
	.loc	1 118 150
	// begin inline asm
	cvt.f32.bf16 %r120, %rs137;
	// end inline asm
	mov.b32 	%f195, %r120;
	// begin inline asm
	cvt.f32.bf16 %r121, %rs138;
	// end inline asm
	mov.b32 	%f196, %r121;
	// begin inline asm
	cvt.f32.bf16 %r122, %rs139;
	// end inline asm
	mov.b32 	%f197, %r122;
	// begin inline asm
	cvt.f32.bf16 %r123, %rs140;
	// end inline asm
	mov.b32 	%f198, %r123;
	.loc	1 119 24
	add.f32 	%f199, %f195, 0f00000000;
	add.f32 	%f200, %f196, 0f00000000;
	add.f32 	%f201, %f197, 0f00000000;
	add.f32 	%f202, %f198, 0f00000000;
	.loc	1 121 17
	neg.f32 	%f203, %f191;
	fma.rn.f32 	%f204, %f203, %f199, 0f00000000;
	neg.f32 	%f205, %f192;
	fma.rn.f32 	%f206, %f205, %f200, 0f00000000;
	neg.f32 	%f207, %f193;
	fma.rn.f32 	%f208, %f207, %f201, 0f00000000;
	neg.f32 	%f209, %f194;
	fma.rn.f32 	%f210, %f209, %f202, 0f00000000;
	.loc	1 124 35
	add.s64 	%rd47, %rd65, %rd85;
	add.s64 	%rd48, %rd87, 64;
	add.s64 	%rd49, %rd87, 128;
	add.s64 	%rd50, %rd87, 192;
	.loc	1 124 55
	// begin inline asm
	mov.u16 %rs149, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs149 }, [ %rd47 + 0 ];
	@!%p59 mov.u16 %rs149, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs150, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs150 }, [ %rd48 + 0 ];
	@!%p59 mov.u16 %rs150, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs151, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs151 }, [ %rd49 + 0 ];
	@!%p59 mov.u16 %rs151, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs152, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs152 }, [ %rd50 + 0 ];
	@!%p59 mov.u16 %rs152, %rs34;
	// end inline asm
	.loc	1 124 122
	// begin inline asm
	cvt.f32.bf16 %r124, %rs149;
	// end inline asm
	mov.b32 	%f211, %r124;
	// begin inline asm
	cvt.f32.bf16 %r125, %rs150;
	// end inline asm
	mov.b32 	%f212, %r125;
	// begin inline asm
	cvt.f32.bf16 %r126, %rs151;
	// end inline asm
	mov.b32 	%f213, %r126;
	// begin inline asm
	cvt.f32.bf16 %r127, %rs152;
	// end inline asm
	mov.b32 	%f214, %r127;
	.loc	1 125 35
	add.s64 	%rd51, %rd66, %rd86;
	add.s64 	%rd52, %rd88, 64;
	add.s64 	%rd53, %rd88, 128;
	add.s64 	%rd54, %rd88, 192;
	.loc	1 125 55
	// begin inline asm
	mov.u16 %rs161, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs161 }, [ %rd51 + 0 ];
	@!%p59 mov.u16 %rs161, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs162, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs162 }, [ %rd52 + 0 ];
	@!%p59 mov.u16 %rs162, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs163, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs163 }, [ %rd53 + 0 ];
	@!%p59 mov.u16 %rs163, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs164, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs164 }, [ %rd54 + 0 ];
	@!%p59 mov.u16 %rs164, %rs34;
	// end inline asm
	.loc	1 125 122
	// begin inline asm
	cvt.f32.bf16 %r128, %rs161;
	// end inline asm
	mov.b32 	%f215, %r128;
	// begin inline asm
	cvt.f32.bf16 %r129, %rs162;
	// end inline asm
	mov.b32 	%f216, %r129;
	// begin inline asm
	cvt.f32.bf16 %r130, %rs163;
	// end inline asm
	mov.b32 	%f217, %r130;
	// begin inline asm
	cvt.f32.bf16 %r131, %rs164;
	// end inline asm
	mov.b32 	%f218, %r131;
	.loc	1 126 24
	add.f32 	%f219, %f211, %f215;
	add.f32 	%f220, %f212, %f216;
	add.f32 	%f221, %f213, %f217;
	add.f32 	%f222, %f214, %f218;
	.loc	1 127 24
	mul.f32 	%f223, %f190, %f219;
	mul.f32 	%f224, %f190, %f220;
	mul.f32 	%f225, %f190, %f221;
	mul.f32 	%f226, %f190, %f222;
	.loc	1 128 35
	add.s64 	%rd56, %rd55, 64;
	add.s64 	%rd57, %rd55, 128;
	add.s64 	%rd58, %rd55, 192;
	.loc	1 128 77
	// begin inline asm
	mov.u16 %rs173, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs173 }, [ %rd55 + 0 ];
	@!%p59 mov.u16 %rs173, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs174, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs174 }, [ %rd56 + 0 ];
	@!%p59 mov.u16 %rs174, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs175, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs175 }, [ %rd57 + 0 ];
	@!%p59 mov.u16 %rs175, %rs34;
	// end inline asm
	// begin inline asm
	mov.u16 %rs176, 0x0;
	@%p59 ld.global.L1::evict_last.b16 { %rs176 }, [ %rd58 + 0 ];
	@!%p59 mov.u16 %rs176, %rs34;
	// end inline asm
	.loc	1 128 144
	// begin inline asm
	cvt.f32.bf16 %r132, %rs173;
	// end inline asm
	mov.b32 	%f227, %r132;
	// begin inline asm
	cvt.f32.bf16 %r133, %rs174;
	// end inline asm
	mov.b32 	%f228, %r133;
	// begin inline asm
	cvt.f32.bf16 %r134, %rs175;
	// end inline asm
	mov.b32 	%f229, %r134;
	// begin inline asm
	cvt.f32.bf16 %r135, %rs176;
	// end inline asm
	mov.b32 	%f230, %r135;
	.loc	1 129 24
	add.f32 	%f231, %f227, 0f00000000;
	add.f32 	%f232, %f228, 0f00000000;
	add.f32 	%f233, %f229, 0f00000000;
	add.f32 	%f234, %f230, 0f00000000;
	.loc	1 130 24
	mul.f32 	%f235, %f223, %f231;
	mul.f32 	%f236, %f224, %f232;
	mul.f32 	%f237, %f225, %f233;
	mul.f32 	%f238, %f226, %f234;
	.loc	1 0 0
	selp.f32 	%f239, %f204, %f235, %p134;
	selp.f32 	%f240, %f206, %f236, %p134;
	selp.f32 	%f241, %f208, %f237, %p134;
	selp.f32 	%f242, %f210, %f238, %p134;
	.loc	1 134 24
	add.f32 	%f243, %f13, %f71;
	add.f32 	%f244, %f14, %f72;
	add.f32 	%f245, %f15, %f73;
	add.f32 	%f246, %f16, %f74;
	.loc	1 135 24
	mul.f32 	%f247, %f243, %f141;
	mul.f32 	%f248, %f244, %f141;
	mul.f32 	%f249, %f245, %f141;
	mul.f32 	%f250, %f246, %f141;
	.loc	1 136 24
	add.f32 	%f251, %f75, 0f00000000;
	add.f32 	%f252, %f76, 0f00000000;
	add.f32 	%f253, %f77, 0f00000000;
	add.f32 	%f254, %f78, 0f00000000;
	.loc	1 137 24
	mul.f32 	%f255, %f251, %f247;
	mul.f32 	%f256, %f252, %f248;
	mul.f32 	%f257, %f253, %f249;
	mul.f32 	%f258, %f254, %f250;
	.loc	1 139 24
	mul.f32 	%f259, %f255, %f63;
	mul.f32 	%f260, %f256, %f64;
	mul.f32 	%f261, %f257, %f65;
	mul.f32 	%f262, %f258, %f66;
	bar.sync 	0;
	st.shared.f32 	[%r205], %f259;
	st.shared.f32 	[%r205+36], %f260;
	st.shared.f32 	[%r205+72], %f261;
	st.shared.f32 	[%r205+108], %f262;
	bar.sync 	0;
	ld.shared.f32 	%f263, [%r211];
	ld.shared.f32 	%f264, [%r211+1152];
	ld.shared.f32 	%f265, [%r211+2304];
	ld.shared.f32 	%f266, [%r211+3456];
	.loc	1 142 25
	fma.rn.f32 	%f267, %f67, %f239, %f263;
	fma.rn.f32 	%f268, %f68, %f240, %f264;
	fma.rn.f32 	%f269, %f69, %f241, %f265;
	fma.rn.f32 	%f270, %f70, %f242, %f266;
	.loc	1 144 32
	add.s64 	%rd59, %rd61, %rd71;
	.loc	1 144 55
	mov.b32 	%r136, %f189;
	// begin inline asm
	cvt.rn.bf16.f32 %rs177, %r136;
	// end inline asm
	mov.b32 	%r137, %f178;
	// begin inline asm
	cvt.rn.bf16.f32 %rs178, %r137;
	// end inline asm
	mov.b32 	%r138, %f167;
	// begin inline asm
	cvt.rn.bf16.f32 %rs179, %r138;
	// end inline asm
	mov.b32 	%r139, %f156;
	// begin inline asm
	cvt.rn.bf16.f32 %rs180, %r139;
	// end inline asm
	bar.sync 	0;
	mad.lo.s32 	%r219, %r152, 132, %r208;
	shl.b32 	%r220, %r219, 1;
	add.s32 	%r221, %r204, %r220;
	st.shared.u16 	[%r221], %rs177;
	st.shared.u16 	[%r221+64], %rs178;
	st.shared.u16 	[%r221+128], %rs179;
	st.shared.u16 	[%r221+192], %rs180;
	bar.sync 	0;
	mad.lo.s32 	%r222, %r150, 132, %r218;
	shl.b32 	%r223, %r222, 1;
	add.s32 	%r224, %r204, %r223;
	ld.shared.v2.u32 	{%r140, %r141}, [%r224];
	// begin inline asm
	@%p1 st.global.v2.b32 [ %rd59 + 0 ], { %r140, %r141 };
	// end inline asm
	.loc	1 145 32
	add.s64 	%rd60, %rd62, %rd71;
	.loc	1 145 56
	mov.b32 	%r142, %f267;
	// begin inline asm
	cvt.rn.bf16.f32 %rs181, %r142;
	// end inline asm
	mov.b32 	%r143, %f268;
	// begin inline asm
	cvt.rn.bf16.f32 %rs182, %r143;
	// end inline asm
	mov.b32 	%r144, %f269;
	// begin inline asm
	cvt.rn.bf16.f32 %rs183, %r144;
	// end inline asm
	mov.b32 	%r145, %f270;
	// begin inline asm
	cvt.rn.bf16.f32 %rs184, %r145;
	// end inline asm
	bar.sync 	0;
	st.shared.u16 	[%r221], %rs181;
	st.shared.u16 	[%r221+64], %rs182;
	st.shared.u16 	[%r221+128], %rs183;
	st.shared.u16 	[%r221+192], %rs184;
	bar.sync 	0;
	ld.shared.v2.u32 	{%r146, %r147}, [%r224];
	// begin inline asm
	@%p1 st.global.v2.b32 [ %rd60 + 0 ], { %r146, %r147 };
	// end inline asm
	.loc	1 51 4
	ret;
$L__tmp4:
$L__func_end0:

}
	.file	1 "/opt/inductor_cache/j7/cj7ile7uzareqr5ehayxmzrhk2k7dljr62gyn7edkfjuybf342qj.py"
	.file	2 "/usr/local/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 11
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 197
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 106
.b8 55
.b8 105
.b8 108
.b8 101
.b8 55
.b8 117
.b8 122
.b8 97
.b8 114
.b8 101
.b8 113
.b8 114
.b8 53
.b8 101
.b8 104
.b8 97
.b8 121
.b8 120
.b8 109
.b8 122
.b8 114
.b8 104
.b8 107
.b8 50
.b8 107
.b8 55
.b8 100
.b8 108
.b8 106
.b8 114
.b8 54
.b8 50
.b8 103
.b8 121
.b8 110
.b8 55
.b8 101
.b8 100
.b8 107
.b8 102
.b8 106
.b8 117
.b8 121
.b8 98
.b8 102
.b8 51
.b8 52
.b8 50
.b8 113
.b8 106
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 111
.b8 112
.b8 116
.b8 47
.b8 105
.b8 110
.b8 100
.b8 117
.b8 99
.b8 116
.b8 111
.b8 114
.b8 95
.b8 99
.b8 97
.b8 99
.b8 104
.b8 101
.b8 47
.b8 106
.b8 55
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 95
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 120
.b8 4
.b32 120
.b64 $L__tmp1
.b64 $L__tmp2
.b8 1
.b8 48
.b8 25
.b8 4
.b32 120
.b64 $L__tmp2
.b64 $L__tmp3
.b8 1
.b8 49
.b8 27
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}
