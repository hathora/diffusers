//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_90a
.address_size 64

	// .globl	triton_
.extern .shared .align 16 .b8 global_smem[];
.global .align 1 .b8 _$_str[11] = {95, 95, 67, 85, 68, 65, 95, 70, 84, 90};

.visible .entry triton_(
	.param .u64 triton__param_0,
	.param .u64 triton__param_1,
	.param .u64 triton__param_2,
	.param .u64 triton__param_3,
	.param .u64 triton__param_4,
	.param .u64 triton__param_5,
	.param .u32 triton__param_6,
	.param .u32 triton__param_7
)
.maxntid 512, 1, 1
{
	.reg .pred 	%p<110>;
	.reg .b16 	%rs<62>;
	.reg .b32 	%r<547>;
	.reg .f32 	%f<786>;
	.reg .b64 	%rd<45>;
	.loc	1 18 0
$L__func_begin0:
	.loc	1 18 0

	ld.param.u64 	%rd22, [triton__param_5];
	ld.param.u64 	%rd21, [triton__param_3];
	ld.param.u64 	%rd20, [triton__param_2];
	ld.param.u64 	%rd19, [triton__param_1];
	ld.param.u64 	%rd18, [triton__param_0];
$L__tmp0:
	.loc	1 21 28
	// begin inline asm
	mov.u32 %r9, %ctaid.x;
	// end inline asm
	.loc	1 22 44
	mov.u32 	%r1, %tid.x;
	bfe.u32 	%r11, %r1, 6, 3;
	ld.param.u64 	%rd23, [triton__param_4];
	.loc	1 24 33
	shl.b32 	%r12, %r1, 3;
	and.b32  	%r13, %r12, 504;
	and.b32  	%r14, %r1, 511;
	mad.lo.s32 	%r15, %r11, 520, %r13;
	shl.b32 	%r16, %r15, 1;
	mov.u32 	%r17, global_smem;
	add.s32 	%r2, %r17, %r16;
	shl.b32 	%r18, %r14, 1;
	add.s32 	%r3, %r17, %r18;
	.loc	1 29 36
	mul.wide.u32 	%rd1, %r14, 2;
	add.s64 	%rd42, %rd23, %rd1;
	or.b64  	%rd24, %rd1, 12288;
	add.s64 	%rd41, %rd21, %rd24;
	add.s64 	%rd40, %rd20, %rd24;
	mul.lo.s32 	%r19, %r11, 3072;
	mad.lo.s32 	%r20, %r9, 24576, %r19;
	or.b32  	%r4, %r20, %r13;
	mov.b32 	%r25, 0;
	mov.f32 	%f97, 0f00000000;
	mov.pred 	%p1, -1;
	mov.u16 	%rs10, 0;
	mov.f32 	%f98, 0f3F800000;
	mov.f32 	%f738, %f97;
	mov.f32 	%f739, %f97;
	mov.f32 	%f740, %f97;
	mov.f32 	%f741, %f97;
	mov.f32 	%f742, %f97;
	mov.f32 	%f743, %f97;
	mov.f32 	%f744, %f97;
	mov.f32 	%f745, %f97;
	mov.f32 	%f746, %f97;
	mov.f32 	%f747, %f97;
	mov.f32 	%f748, %f97;
	mov.f32 	%f749, %f97;
	mov.f32 	%f750, %f97;
	mov.f32 	%f751, %f97;
	mov.f32 	%f752, %f97;
	mov.f32 	%f753, %f97;
	mov.f32 	%f754, %f97;
	mov.f32 	%f755, %f97;
	mov.f32 	%f756, %f97;
	mov.f32 	%f757, %f97;
	mov.f32 	%f758, %f97;
	mov.f32 	%f759, %f97;
	mov.f32 	%f760, %f97;
	mov.f32 	%f761, %f97;
	mov.u32 	%r545, %r25;
	bra.uni 	$L__BB0_1;
$L__BB0_3:
	.loc	1 50 55
	mov.b32 	%r89, %f25;
	// begin inline asm
	cvt.rn.bf16.f32 %rs26, %r89;
	// end inline asm
	mov.b32 	%r90, %f26;
	// begin inline asm
	cvt.rn.bf16.f32 %rs27, %r90;
	// end inline asm
	mov.b32 	%r91, %f27;
	// begin inline asm
	cvt.rn.bf16.f32 %rs28, %r91;
	// end inline asm
	mov.b32 	%r92, %f28;
	// begin inline asm
	cvt.rn.bf16.f32 %rs29, %r92;
	// end inline asm
	mov.b32 	%r93, %f29;
	// begin inline asm
	cvt.rn.bf16.f32 %rs30, %r93;
	// end inline asm
	mov.b32 	%r94, %f30;
	// begin inline asm
	cvt.rn.bf16.f32 %rs31, %r94;
	// end inline asm
	mov.b32 	%r95, %f31;
	// begin inline asm
	cvt.rn.bf16.f32 %rs32, %r95;
	// end inline asm
	mov.b32 	%r96, %f32;
	// begin inline asm
	cvt.rn.bf16.f32 %rs33, %r96;
	// end inline asm
	bar.sync 	0;
	st.shared.u16 	[%r3], %rs26;
	st.shared.u16 	[%r3+1040], %rs27;
	st.shared.u16 	[%r3+2080], %rs28;
	st.shared.u16 	[%r3+3120], %rs29;
	st.shared.u16 	[%r3+4160], %rs30;
	st.shared.u16 	[%r3+5200], %rs31;
	st.shared.u16 	[%r3+6240], %rs32;
	st.shared.u16 	[%r3+7280], %rs33;
	bar.sync 	0;
	ld.shared.v4.u32 	{%r97, %r98, %r99, %r100}, [%r2];
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd31 + 0 ], { %r97, %r98, %r99, %r100 };
	// end inline asm
	.loc	1 29 36
	add.s32 	%r6, %r545, 512;
	add.s64 	%rd42, %rd42, 1024;
	add.s64 	%rd41, %rd41, 1024;
	add.s64 	%rd40, %rd40, 1024;
	setp.lt.u32 	%p19, %r545, 2560;
	mov.f32 	%f738, %f762;
	mov.f32 	%f739, %f763;
	mov.f32 	%f740, %f764;
	mov.f32 	%f741, %f765;
	mov.f32 	%f742, %f766;
	mov.f32 	%f743, %f767;
	mov.f32 	%f744, %f768;
	mov.f32 	%f745, %f769;
	mov.f32 	%f746, %f778;
	mov.f32 	%f747, %f779;
	mov.f32 	%f748, %f780;
	mov.f32 	%f749, %f781;
	mov.f32 	%f750, %f782;
	mov.f32 	%f751, %f783;
	mov.f32 	%f752, %f784;
	mov.f32 	%f753, %f785;
	mov.f32 	%f754, %f770;
	mov.f32 	%f755, %f771;
	mov.f32 	%f756, %f772;
	mov.f32 	%f757, %f773;
	mov.f32 	%f758, %f774;
	mov.f32 	%f759, %f775;
	mov.f32 	%f760, %f776;
	mov.f32 	%f761, %f777;
	mov.u32 	%r545, %r6;
	@%p19 bra 	$L__BB0_1;
	bra.uni 	$L__BB0_4;
$L__BB0_1:
	.loc	1 33 34
	add.s32 	%r56, %r4, %r545;
	mul.wide.s32 	%rd30, %r56, 2;
	add.s64 	%rd25, %rd19, %rd30;
	.loc	1 33 51
	// begin inline asm
	mov.u32 %r21, 0x0;
	mov.u32 %r22, 0x0;
	mov.u32 %r23, 0x0;
	mov.u32 %r24, 0x0;
	@%p1 ld.global.L1::evict_first.v4.b32 { %r21, %r22, %r23, %r24 }, [ %rd25 + 0 ];
	@!%p1 mov.u32 %r21, %r25;
	@!%p1 mov.u32 %r22, %r25;
	@!%p1 mov.u32 %r23, %r25;
	@!%p1 mov.u32 %r24, %r25;
	// end inline asm
	.loc	1 33 103
	bar.sync 	0;
	st.shared.v4.b32 	[%r2], {%r21, %r22, %r23, %r24};
	bar.sync 	0;
	ld.shared.u16 	%rs1, [%r3];
	ld.shared.u16 	%rs2, [%r3+1040];
	ld.shared.u16 	%rs3, [%r3+2080];
	ld.shared.u16 	%rs4, [%r3+3120];
	ld.shared.u16 	%rs5, [%r3+4160];
	ld.shared.u16 	%rs6, [%r3+5200];
	ld.shared.u16 	%rs7, [%r3+6240];
	ld.shared.u16 	%rs8, [%r3+7280];
	// begin inline asm
	cvt.f32.bf16 %r29, %rs1;
	// end inline asm
	mov.b32 	%f100, %r29;
	// begin inline asm
	cvt.f32.bf16 %r30, %rs2;
	// end inline asm
	mov.b32 	%f101, %r30;
	// begin inline asm
	cvt.f32.bf16 %r31, %rs3;
	// end inline asm
	mov.b32 	%f102, %r31;
	// begin inline asm
	cvt.f32.bf16 %r32, %rs4;
	// end inline asm
	mov.b32 	%f103, %r32;
	// begin inline asm
	cvt.f32.bf16 %r33, %rs5;
	// end inline asm
	mov.b32 	%f104, %r33;
	// begin inline asm
	cvt.f32.bf16 %r34, %rs6;
	// end inline asm
	mov.b32 	%f105, %r34;
	// begin inline asm
	cvt.f32.bf16 %r35, %rs7;
	// end inline asm
	mov.b32 	%f106, %r35;
	// begin inline asm
	cvt.f32.bf16 %r36, %rs8;
	// end inline asm
	mov.b32 	%f107, %r36;
	.loc	1 34 46
	// begin inline asm
	mov.u16 %rs9, 0x0;
	@%p1 ld.global.L1::evict_last.b16 { %rs9 }, [ %rd40 + 0 ];
	@!%p1 mov.u16 %rs9, %rs10;
	// end inline asm
	.loc	1 34 97
	// begin inline asm
	cvt.f32.bf16 %r37, %rs9;
	// end inline asm
	mov.b32 	%f108, %r37;
	.loc	1 35 46
	// begin inline asm
	mov.u16 %rs12, 0x0;
	@%p1 ld.global.L1::evict_last.b16 { %rs12 }, [ %rd41 + 0 ];
	@!%p1 mov.u16 %rs12, %rs10;
	// end inline asm
	.loc	1 35 97
	// begin inline asm
	cvt.f32.bf16 %r38, %rs12;
	// end inline asm
	mov.b32 	%f109, %r38;
	.loc	1 36 38
	add.s64 	%rd31, %rd18, %rd30;
	.loc	1 36 55
	// begin inline asm
	mov.u32 %r39, 0x0;
	mov.u32 %r40, 0x0;
	mov.u32 %r41, 0x0;
	mov.u32 %r42, 0x0;
	@%p1 ld.global.L1::evict_first.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd31 + 0 ];
	@!%p1 mov.u32 %r39, %r25;
	@!%p1 mov.u32 %r40, %r25;
	@!%p1 mov.u32 %r41, %r25;
	@!%p1 mov.u32 %r42, %r25;
	// end inline asm
	.loc	1 36 107
	bar.sync 	0;
	st.shared.v4.b32 	[%r2], {%r39, %r40, %r41, %r42};
	bar.sync 	0;
	ld.shared.u16 	%rs15, [%r3];
	ld.shared.u16 	%rs16, [%r3+1040];
	ld.shared.u16 	%rs17, [%r3+2080];
	ld.shared.u16 	%rs18, [%r3+3120];
	ld.shared.u16 	%rs19, [%r3+4160];
	ld.shared.u16 	%rs20, [%r3+5200];
	ld.shared.u16 	%rs21, [%r3+6240];
	ld.shared.u16 	%rs22, [%r3+7280];
	// begin inline asm
	cvt.f32.bf16 %r47, %rs15;
	// end inline asm
	mov.b32 	%f110, %r47;
	// begin inline asm
	cvt.f32.bf16 %r48, %rs16;
	// end inline asm
	mov.b32 	%f111, %r48;
	// begin inline asm
	cvt.f32.bf16 %r49, %rs17;
	// end inline asm
	mov.b32 	%f112, %r49;
	// begin inline asm
	cvt.f32.bf16 %r50, %rs18;
	// end inline asm
	mov.b32 	%f113, %r50;
	// begin inline asm
	cvt.f32.bf16 %r51, %rs19;
	// end inline asm
	mov.b32 	%f114, %r51;
	// begin inline asm
	cvt.f32.bf16 %r52, %rs20;
	// end inline asm
	mov.b32 	%f115, %r52;
	// begin inline asm
	cvt.f32.bf16 %r53, %rs21;
	// end inline asm
	mov.b32 	%f116, %r53;
	// begin inline asm
	cvt.f32.bf16 %r54, %rs22;
	// end inline asm
	mov.b32 	%f117, %r54;
	.loc	1 37 39
	// begin inline asm
	mov.u16 %rs23, 0x0;
	@%p1 ld.global.L1::evict_last.b16 { %rs23 }, [ %rd42 + 0 ];
	@!%p1 mov.u16 %rs23, %rs10;
	// end inline asm
	.loc	1 37 90
	// begin inline asm
	cvt.f32.bf16 %r55, %rs23;
	// end inline asm
	mov.b32 	%f118, %r55;
	.loc	1 38 22
	add.f32 	%f119, %f108, %f109;
	.loc	1 39 22
	add.f32 	%f120, %f110, %f118;
	add.f32 	%f121, %f111, %f118;
	add.f32 	%f122, %f112, %f118;
	add.f32 	%f123, %f113, %f118;
	add.f32 	%f124, %f114, %f118;
	add.f32 	%f125, %f115, %f118;
	add.f32 	%f126, %f116, %f118;
	add.f32 	%f127, %f117, %f118;
	.loc	1 41 22
	fma.rn.f32 	%f25, %f119, %f120, %f100;
	fma.rn.f32 	%f26, %f119, %f121, %f101;
	fma.rn.f32 	%f27, %f119, %f122, %f102;
	fma.rn.f32 	%f28, %f119, %f123, %f103;
	fma.rn.f32 	%f29, %f119, %f124, %f104;
	fma.rn.f32 	%f30, %f119, %f125, %f105;
	fma.rn.f32 	%f31, %f119, %f126, %f106;
	fma.rn.f32 	%f32, %f119, %f127, %f107;
	.loc	1 45 66
	setp.eq.s32 	%p17, %r545, 0;
	mov.f32 	%f762, %f98;
	mov.f32 	%f763, %f98;
	mov.f32 	%f764, %f98;
	mov.f32 	%f765, %f98;
	mov.f32 	%f766, %f98;
	mov.f32 	%f767, %f98;
	mov.f32 	%f768, %f98;
	mov.f32 	%f769, %f98;
	mov.f32 	%f770, %f25;
	mov.f32 	%f771, %f26;
	mov.f32 	%f772, %f27;
	mov.f32 	%f773, %f28;
	mov.f32 	%f774, %f29;
	mov.f32 	%f775, %f30;
	mov.f32 	%f776, %f31;
	mov.f32 	%f777, %f32;
	mov.f32 	%f778, %f97;
	mov.f32 	%f779, %f97;
	mov.f32 	%f780, %f97;
	mov.f32 	%f781, %f97;
	mov.f32 	%f782, %f97;
	mov.f32 	%f783, %f97;
	mov.f32 	%f784, %f97;
	mov.f32 	%f785, %f97;
$L__tmp1:
	.loc	2 142 7
	@%p17 bra 	$L__BB0_3;
	.loc	2 147 24
	sub.f32 	%f128, %f25, %f754;
	sub.f32 	%f129, %f26, %f755;
	sub.f32 	%f130, %f27, %f756;
	sub.f32 	%f131, %f28, %f757;
	sub.f32 	%f132, %f29, %f758;
	sub.f32 	%f133, %f30, %f759;
	sub.f32 	%f134, %f31, %f760;
	sub.f32 	%f135, %f32, %f761;
	.loc	2 148 30
	add.f32 	%f762, %f738, 0f3F800000;
	add.f32 	%f763, %f739, 0f3F800000;
	add.f32 	%f764, %f740, 0f3F800000;
	add.f32 	%f765, %f741, 0f3F800000;
	add.f32 	%f766, %f742, 0f3F800000;
	add.f32 	%f767, %f743, 0f3F800000;
	add.f32 	%f768, %f744, 0f3F800000;
	add.f32 	%f769, %f745, 0f3F800000;
	.loc	2 149 34
	mov.b32 	%r66, %f128;
	mov.b32 	%r67, %f762;
	// begin inline asm
	div.full.f32 %r65, %r66, %r67;
	// end inline asm
	mov.b32 	%f136, %r65;
	mov.b32 	%r69, %f129;
	mov.b32 	%r70, %f763;
	// begin inline asm
	div.full.f32 %r68, %r69, %r70;
	// end inline asm
	mov.b32 	%f137, %r68;
	mov.b32 	%r72, %f130;
	mov.b32 	%r73, %f764;
	// begin inline asm
	div.full.f32 %r71, %r72, %r73;
	// end inline asm
	mov.b32 	%f138, %r71;
	mov.b32 	%r75, %f131;
	mov.b32 	%r76, %f765;
	// begin inline asm
	div.full.f32 %r74, %r75, %r76;
	// end inline asm
	mov.b32 	%f139, %r74;
	mov.b32 	%r78, %f132;
	mov.b32 	%r79, %f766;
	// begin inline asm
	div.full.f32 %r77, %r78, %r79;
	// end inline asm
	mov.b32 	%f140, %r77;
	mov.b32 	%r81, %f133;
	mov.b32 	%r82, %f767;
	// begin inline asm
	div.full.f32 %r80, %r81, %r82;
	// end inline asm
	mov.b32 	%f141, %r80;
	mov.b32 	%r84, %f134;
	mov.b32 	%r85, %f768;
	// begin inline asm
	div.full.f32 %r83, %r84, %r85;
	// end inline asm
	mov.b32 	%f142, %r83;
	mov.b32 	%r87, %f135;
	mov.b32 	%r88, %f769;
	// begin inline asm
	div.full.f32 %r86, %r87, %r88;
	// end inline asm
	mov.b32 	%f143, %r86;
	.loc	2 149 26
	add.f32 	%f770, %f754, %f136;
	add.f32 	%f771, %f755, %f137;
	add.f32 	%f772, %f756, %f138;
	add.f32 	%f773, %f757, %f139;
	add.f32 	%f774, %f758, %f140;
	add.f32 	%f775, %f759, %f141;
	add.f32 	%f776, %f760, %f142;
	add.f32 	%f777, %f761, %f143;
	.loc	2 150 39
	sub.f32 	%f144, %f25, %f770;
	sub.f32 	%f145, %f26, %f771;
	sub.f32 	%f146, %f27, %f772;
	sub.f32 	%f147, %f28, %f773;
	sub.f32 	%f148, %f29, %f774;
	sub.f32 	%f149, %f30, %f775;
	sub.f32 	%f150, %f31, %f776;
	sub.f32 	%f151, %f32, %f777;
	.loc	2 150 22
	fma.rn.f32 	%f778, %f128, %f144, %f746;
	fma.rn.f32 	%f779, %f129, %f145, %f747;
	fma.rn.f32 	%f780, %f130, %f146, %f748;
	fma.rn.f32 	%f781, %f131, %f147, %f749;
	fma.rn.f32 	%f782, %f132, %f148, %f750;
	fma.rn.f32 	%f783, %f133, %f149, %f751;
	fma.rn.f32 	%f784, %f134, %f150, %f752;
	fma.rn.f32 	%f785, %f135, %f151, %f753;
	bra.uni 	$L__BB0_3;
$L__tmp2:
$L__BB0_4:
	.loc	1 24 33
	and.b32  	%r318, %r1, 31;
$L__tmp3:
	.loc	2 168 46
	bar.sync 	0;
	mov.b32 	%r319, %f770;
	shfl.sync.bfly.b32	%r320, %r319, 16, 31, -1;
	mov.b32 	%f152, %r320;
	mov.b32 	%r321, %f778;
	shfl.sync.bfly.b32	%r322, %r321, 16, 31, -1;
	mov.b32 	%f153, %r322;
	mov.b32 	%r323, %f762;
	shfl.sync.bfly.b32	%r102, %r323, 16, 31, -1;
	mov.b32 	%f154, %r102;
	.loc	2 156 21
	sub.f32 	%f155, %f152, %f770;
	.loc	2 157 28
	add.f32 	%f156, %f762, %f154;
	.loc	2 158 39
	setp.eq.f32 	%p50, %f156, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r103, %f156;
	// begin inline asm
	div.full.f32 %r101, %r102, %r103;
	// end inline asm
	mov.b32 	%f157, %r101;
	.loc	2 158 49
	selp.f32 	%f158, 0f00000000, %f157, %p50;
	.loc	2 160 17
	fma.rn.f32 	%f159, %f155, %f158, %f770;
	.loc	2 161 15
	add.f32 	%f160, %f778, %f153;
	.loc	2 161 30
	mul.f32 	%f161, %f155, %f155;
	.loc	2 161 38
	mul.f32 	%f162, %f762, %f161;
	.loc	2 161 22
	fma.rn.f32 	%f163, %f162, %f158, %f160;
	.loc	2 168 46
	mov.b32 	%r324, %f159;
	shfl.sync.bfly.b32	%r325, %r324, 8, 31, -1;
	mov.b32 	%f164, %r325;
	mov.b32 	%r326, %f163;
	shfl.sync.bfly.b32	%r327, %r326, 8, 31, -1;
	mov.b32 	%f165, %r327;
	shfl.sync.bfly.b32	%r105, %r103, 8, 31, -1;
	mov.b32 	%f166, %r105;
	.loc	2 156 21
	sub.f32 	%f167, %f164, %f159;
	.loc	2 157 28
	add.f32 	%f168, %f156, %f166;
	.loc	2 158 39
	setp.eq.f32 	%p51, %f168, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r106, %f168;
	// begin inline asm
	div.full.f32 %r104, %r105, %r106;
	// end inline asm
	mov.b32 	%f169, %r104;
	.loc	2 158 49
	selp.f32 	%f170, 0f00000000, %f169, %p51;
	.loc	2 160 17
	fma.rn.f32 	%f171, %f167, %f170, %f159;
	.loc	2 161 15
	add.f32 	%f172, %f163, %f165;
	.loc	2 161 30
	mul.f32 	%f173, %f167, %f167;
	.loc	2 161 38
	mul.f32 	%f174, %f156, %f173;
	.loc	2 161 22
	fma.rn.f32 	%f175, %f170, %f174, %f172;
	.loc	2 168 46
	mov.b32 	%r328, %f171;
	shfl.sync.bfly.b32	%r329, %r328, 4, 31, -1;
	mov.b32 	%f176, %r329;
	mov.b32 	%r330, %f175;
	shfl.sync.bfly.b32	%r331, %r330, 4, 31, -1;
	mov.b32 	%f177, %r331;
	shfl.sync.bfly.b32	%r108, %r106, 4, 31, -1;
	mov.b32 	%f178, %r108;
	.loc	2 156 21
	sub.f32 	%f179, %f176, %f171;
	.loc	2 157 28
	add.f32 	%f180, %f168, %f178;
	.loc	2 158 39
	setp.eq.f32 	%p52, %f180, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r109, %f180;
	// begin inline asm
	div.full.f32 %r107, %r108, %r109;
	// end inline asm
	mov.b32 	%f181, %r107;
	.loc	2 158 49
	selp.f32 	%f182, 0f00000000, %f181, %p52;
	.loc	2 160 17
	fma.rn.f32 	%f183, %f179, %f182, %f171;
	.loc	2 161 15
	add.f32 	%f184, %f175, %f177;
	.loc	2 161 30
	mul.f32 	%f185, %f179, %f179;
	.loc	2 161 38
	mul.f32 	%f186, %f168, %f185;
	.loc	2 161 22
	fma.rn.f32 	%f187, %f182, %f186, %f184;
	.loc	2 168 46
	mov.b32 	%r332, %f183;
	shfl.sync.bfly.b32	%r333, %r332, 2, 31, -1;
	mov.b32 	%f188, %r333;
	mov.b32 	%r334, %f187;
	shfl.sync.bfly.b32	%r335, %r334, 2, 31, -1;
	mov.b32 	%f189, %r335;
	shfl.sync.bfly.b32	%r111, %r109, 2, 31, -1;
	mov.b32 	%f190, %r111;
	.loc	2 156 21
	sub.f32 	%f191, %f188, %f183;
	.loc	2 157 28
	add.f32 	%f192, %f180, %f190;
	.loc	2 158 39
	setp.eq.f32 	%p53, %f192, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r112, %f192;
	// begin inline asm
	div.full.f32 %r110, %r111, %r112;
	// end inline asm
	mov.b32 	%f193, %r110;
	.loc	2 158 49
	selp.f32 	%f194, 0f00000000, %f193, %p53;
	.loc	2 160 17
	fma.rn.f32 	%f195, %f191, %f194, %f183;
	.loc	2 161 15
	add.f32 	%f196, %f187, %f189;
	.loc	2 161 30
	mul.f32 	%f197, %f191, %f191;
	.loc	2 161 38
	mul.f32 	%f198, %f180, %f197;
	.loc	2 161 22
	fma.rn.f32 	%f199, %f194, %f198, %f196;
	.loc	2 168 46
	mov.b32 	%r336, %f195;
	shfl.sync.bfly.b32	%r337, %r336, 1, 31, -1;
	mov.b32 	%f200, %r337;
	mov.b32 	%r338, %f199;
	shfl.sync.bfly.b32	%r339, %r338, 1, 31, -1;
	mov.b32 	%f201, %r339;
	shfl.sync.bfly.b32	%r114, %r112, 1, 31, -1;
	mov.b32 	%f202, %r114;
	.loc	2 156 21
	sub.f32 	%f203, %f200, %f195;
	.loc	2 157 28
	add.f32 	%f204, %f192, %f202;
	.loc	2 158 39
	setp.eq.f32 	%p54, %f204, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r115, %f204;
	// begin inline asm
	div.full.f32 %r113, %r114, %r115;
	// end inline asm
	mov.b32 	%f205, %r113;
	.loc	2 158 49
	selp.f32 	%f206, 0f00000000, %f205, %p54;
	.loc	2 160 17
	fma.rn.f32 	%f207, %f203, %f206, %f195;
	.loc	2 161 15
	add.f32 	%f208, %f199, %f201;
	.loc	2 161 30
	mul.f32 	%f209, %f203, %f203;
	.loc	2 161 38
	mul.f32 	%f210, %f192, %f209;
	.loc	2 161 22
	fma.rn.f32 	%f211, %f206, %f210, %f208;
	.loc	2 168 46
	mov.b32 	%r340, %f771;
	shfl.sync.bfly.b32	%r341, %r340, 16, 31, -1;
	mov.b32 	%f212, %r341;
	mov.b32 	%r342, %f779;
	shfl.sync.bfly.b32	%r343, %r342, 16, 31, -1;
	mov.b32 	%f213, %r343;
	mov.b32 	%r344, %f763;
	shfl.sync.bfly.b32	%r117, %r344, 16, 31, -1;
	mov.b32 	%f214, %r117;
	.loc	2 156 21
	sub.f32 	%f215, %f212, %f771;
	.loc	2 157 28
	add.f32 	%f216, %f763, %f214;
	.loc	2 158 39
	setp.eq.f32 	%p55, %f216, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r118, %f216;
	// begin inline asm
	div.full.f32 %r116, %r117, %r118;
	// end inline asm
	mov.b32 	%f217, %r116;
	.loc	2 158 49
	selp.f32 	%f218, 0f00000000, %f217, %p55;
	.loc	2 160 17
	fma.rn.f32 	%f219, %f215, %f218, %f771;
	.loc	2 161 15
	add.f32 	%f220, %f779, %f213;
	.loc	2 161 30
	mul.f32 	%f221, %f215, %f215;
	.loc	2 161 38
	mul.f32 	%f222, %f763, %f221;
	.loc	2 161 22
	fma.rn.f32 	%f223, %f222, %f218, %f220;
	.loc	2 168 46
	mov.b32 	%r345, %f219;
	shfl.sync.bfly.b32	%r346, %r345, 8, 31, -1;
	mov.b32 	%f224, %r346;
	mov.b32 	%r347, %f223;
	shfl.sync.bfly.b32	%r348, %r347, 8, 31, -1;
	mov.b32 	%f225, %r348;
	shfl.sync.bfly.b32	%r120, %r118, 8, 31, -1;
	mov.b32 	%f226, %r120;
	.loc	2 156 21
	sub.f32 	%f227, %f224, %f219;
	.loc	2 157 28
	add.f32 	%f228, %f216, %f226;
	.loc	2 158 39
	setp.eq.f32 	%p56, %f228, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r121, %f228;
	// begin inline asm
	div.full.f32 %r119, %r120, %r121;
	// end inline asm
	mov.b32 	%f229, %r119;
	.loc	2 158 49
	selp.f32 	%f230, 0f00000000, %f229, %p56;
	.loc	2 160 17
	fma.rn.f32 	%f231, %f227, %f230, %f219;
	.loc	2 161 15
	add.f32 	%f232, %f223, %f225;
	.loc	2 161 30
	mul.f32 	%f233, %f227, %f227;
	.loc	2 161 38
	mul.f32 	%f234, %f216, %f233;
	.loc	2 161 22
	fma.rn.f32 	%f235, %f230, %f234, %f232;
	.loc	2 168 46
	mov.b32 	%r349, %f231;
	shfl.sync.bfly.b32	%r350, %r349, 4, 31, -1;
	mov.b32 	%f236, %r350;
	mov.b32 	%r351, %f235;
	shfl.sync.bfly.b32	%r352, %r351, 4, 31, -1;
	mov.b32 	%f237, %r352;
	shfl.sync.bfly.b32	%r123, %r121, 4, 31, -1;
	mov.b32 	%f238, %r123;
	.loc	2 156 21
	sub.f32 	%f239, %f236, %f231;
	.loc	2 157 28
	add.f32 	%f240, %f228, %f238;
	.loc	2 158 39
	setp.eq.f32 	%p57, %f240, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r124, %f240;
	// begin inline asm
	div.full.f32 %r122, %r123, %r124;
	// end inline asm
	mov.b32 	%f241, %r122;
	.loc	2 158 49
	selp.f32 	%f242, 0f00000000, %f241, %p57;
	.loc	2 160 17
	fma.rn.f32 	%f243, %f239, %f242, %f231;
	.loc	2 161 15
	add.f32 	%f244, %f235, %f237;
	.loc	2 161 30
	mul.f32 	%f245, %f239, %f239;
	.loc	2 161 38
	mul.f32 	%f246, %f228, %f245;
	.loc	2 161 22
	fma.rn.f32 	%f247, %f242, %f246, %f244;
	.loc	2 168 46
	mov.b32 	%r353, %f243;
	shfl.sync.bfly.b32	%r354, %r353, 2, 31, -1;
	mov.b32 	%f248, %r354;
	mov.b32 	%r355, %f247;
	shfl.sync.bfly.b32	%r356, %r355, 2, 31, -1;
	mov.b32 	%f249, %r356;
	shfl.sync.bfly.b32	%r126, %r124, 2, 31, -1;
	mov.b32 	%f250, %r126;
	.loc	2 156 21
	sub.f32 	%f251, %f248, %f243;
	.loc	2 157 28
	add.f32 	%f252, %f240, %f250;
	.loc	2 158 39
	setp.eq.f32 	%p58, %f252, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r127, %f252;
	// begin inline asm
	div.full.f32 %r125, %r126, %r127;
	// end inline asm
	mov.b32 	%f253, %r125;
	.loc	2 158 49
	selp.f32 	%f254, 0f00000000, %f253, %p58;
	.loc	2 160 17
	fma.rn.f32 	%f255, %f251, %f254, %f243;
	.loc	2 161 15
	add.f32 	%f256, %f247, %f249;
	.loc	2 161 30
	mul.f32 	%f257, %f251, %f251;
	.loc	2 161 38
	mul.f32 	%f258, %f240, %f257;
	.loc	2 161 22
	fma.rn.f32 	%f259, %f254, %f258, %f256;
	.loc	2 168 46
	mov.b32 	%r357, %f255;
	shfl.sync.bfly.b32	%r358, %r357, 1, 31, -1;
	mov.b32 	%f260, %r358;
	mov.b32 	%r359, %f259;
	shfl.sync.bfly.b32	%r360, %r359, 1, 31, -1;
	mov.b32 	%f261, %r360;
	shfl.sync.bfly.b32	%r129, %r127, 1, 31, -1;
	mov.b32 	%f262, %r129;
	.loc	2 156 21
	sub.f32 	%f263, %f260, %f255;
	.loc	2 157 28
	add.f32 	%f264, %f252, %f262;
	.loc	2 158 39
	setp.eq.f32 	%p59, %f264, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r130, %f264;
	// begin inline asm
	div.full.f32 %r128, %r129, %r130;
	// end inline asm
	mov.b32 	%f265, %r128;
	.loc	2 158 49
	selp.f32 	%f266, 0f00000000, %f265, %p59;
	.loc	2 160 17
	fma.rn.f32 	%f267, %f263, %f266, %f255;
	.loc	2 161 15
	add.f32 	%f268, %f259, %f261;
	.loc	2 161 30
	mul.f32 	%f269, %f263, %f263;
	.loc	2 161 38
	mul.f32 	%f270, %f252, %f269;
	.loc	2 161 22
	fma.rn.f32 	%f271, %f266, %f270, %f268;
	.loc	2 168 46
	mov.b32 	%r361, %f772;
	shfl.sync.bfly.b32	%r362, %r361, 16, 31, -1;
	mov.b32 	%f272, %r362;
	mov.b32 	%r363, %f780;
	shfl.sync.bfly.b32	%r364, %r363, 16, 31, -1;
	mov.b32 	%f273, %r364;
	mov.b32 	%r365, %f764;
	shfl.sync.bfly.b32	%r132, %r365, 16, 31, -1;
	mov.b32 	%f274, %r132;
	.loc	2 156 21
	sub.f32 	%f275, %f272, %f772;
	.loc	2 157 28
	add.f32 	%f276, %f764, %f274;
	.loc	2 158 39
	setp.eq.f32 	%p60, %f276, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r133, %f276;
	// begin inline asm
	div.full.f32 %r131, %r132, %r133;
	// end inline asm
	mov.b32 	%f277, %r131;
	.loc	2 158 49
	selp.f32 	%f278, 0f00000000, %f277, %p60;
	.loc	2 160 17
	fma.rn.f32 	%f279, %f275, %f278, %f772;
	.loc	2 161 15
	add.f32 	%f280, %f780, %f273;
	.loc	2 161 30
	mul.f32 	%f281, %f275, %f275;
	.loc	2 161 38
	mul.f32 	%f282, %f764, %f281;
	.loc	2 161 22
	fma.rn.f32 	%f283, %f282, %f278, %f280;
	.loc	2 168 46
	mov.b32 	%r366, %f279;
	shfl.sync.bfly.b32	%r367, %r366, 8, 31, -1;
	mov.b32 	%f284, %r367;
	mov.b32 	%r368, %f283;
	shfl.sync.bfly.b32	%r369, %r368, 8, 31, -1;
	mov.b32 	%f285, %r369;
	shfl.sync.bfly.b32	%r135, %r133, 8, 31, -1;
	mov.b32 	%f286, %r135;
	.loc	2 156 21
	sub.f32 	%f287, %f284, %f279;
	.loc	2 157 28
	add.f32 	%f288, %f276, %f286;
	.loc	2 158 39
	setp.eq.f32 	%p61, %f288, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r136, %f288;
	// begin inline asm
	div.full.f32 %r134, %r135, %r136;
	// end inline asm
	mov.b32 	%f289, %r134;
	.loc	2 158 49
	selp.f32 	%f290, 0f00000000, %f289, %p61;
	.loc	2 160 17
	fma.rn.f32 	%f291, %f287, %f290, %f279;
	.loc	2 161 15
	add.f32 	%f292, %f283, %f285;
	.loc	2 161 30
	mul.f32 	%f293, %f287, %f287;
	.loc	2 161 38
	mul.f32 	%f294, %f276, %f293;
	.loc	2 161 22
	fma.rn.f32 	%f295, %f290, %f294, %f292;
	.loc	2 168 46
	mov.b32 	%r370, %f291;
	shfl.sync.bfly.b32	%r371, %r370, 4, 31, -1;
	mov.b32 	%f296, %r371;
	mov.b32 	%r372, %f295;
	shfl.sync.bfly.b32	%r373, %r372, 4, 31, -1;
	mov.b32 	%f297, %r373;
	shfl.sync.bfly.b32	%r138, %r136, 4, 31, -1;
	mov.b32 	%f298, %r138;
	.loc	2 156 21
	sub.f32 	%f299, %f296, %f291;
	.loc	2 157 28
	add.f32 	%f300, %f288, %f298;
	.loc	2 158 39
	setp.eq.f32 	%p62, %f300, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r139, %f300;
	// begin inline asm
	div.full.f32 %r137, %r138, %r139;
	// end inline asm
	mov.b32 	%f301, %r137;
	.loc	2 158 49
	selp.f32 	%f302, 0f00000000, %f301, %p62;
	.loc	2 160 17
	fma.rn.f32 	%f303, %f299, %f302, %f291;
	.loc	2 161 15
	add.f32 	%f304, %f295, %f297;
	.loc	2 161 30
	mul.f32 	%f305, %f299, %f299;
	.loc	2 161 38
	mul.f32 	%f306, %f288, %f305;
	.loc	2 161 22
	fma.rn.f32 	%f307, %f302, %f306, %f304;
	.loc	2 168 46
	mov.b32 	%r374, %f303;
	shfl.sync.bfly.b32	%r375, %r374, 2, 31, -1;
	mov.b32 	%f308, %r375;
	mov.b32 	%r376, %f307;
	shfl.sync.bfly.b32	%r377, %r376, 2, 31, -1;
	mov.b32 	%f309, %r377;
	shfl.sync.bfly.b32	%r141, %r139, 2, 31, -1;
	mov.b32 	%f310, %r141;
	.loc	2 156 21
	sub.f32 	%f311, %f308, %f303;
	.loc	2 157 28
	add.f32 	%f312, %f300, %f310;
	.loc	2 158 39
	setp.eq.f32 	%p63, %f312, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r142, %f312;
	// begin inline asm
	div.full.f32 %r140, %r141, %r142;
	// end inline asm
	mov.b32 	%f313, %r140;
	.loc	2 158 49
	selp.f32 	%f314, 0f00000000, %f313, %p63;
	.loc	2 160 17
	fma.rn.f32 	%f315, %f311, %f314, %f303;
	.loc	2 161 15
	add.f32 	%f316, %f307, %f309;
	.loc	2 161 30
	mul.f32 	%f317, %f311, %f311;
	.loc	2 161 38
	mul.f32 	%f318, %f300, %f317;
	.loc	2 161 22
	fma.rn.f32 	%f319, %f314, %f318, %f316;
	.loc	2 168 46
	mov.b32 	%r378, %f315;
	shfl.sync.bfly.b32	%r379, %r378, 1, 31, -1;
	mov.b32 	%f320, %r379;
	mov.b32 	%r380, %f319;
	shfl.sync.bfly.b32	%r381, %r380, 1, 31, -1;
	mov.b32 	%f321, %r381;
	shfl.sync.bfly.b32	%r144, %r142, 1, 31, -1;
	mov.b32 	%f322, %r144;
	.loc	2 156 21
	sub.f32 	%f323, %f320, %f315;
	.loc	2 157 28
	add.f32 	%f324, %f312, %f322;
	.loc	2 158 39
	setp.eq.f32 	%p64, %f324, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r145, %f324;
	// begin inline asm
	div.full.f32 %r143, %r144, %r145;
	// end inline asm
	mov.b32 	%f325, %r143;
	.loc	2 158 49
	selp.f32 	%f326, 0f00000000, %f325, %p64;
	.loc	2 160 17
	fma.rn.f32 	%f327, %f323, %f326, %f315;
	.loc	2 161 15
	add.f32 	%f328, %f319, %f321;
	.loc	2 161 30
	mul.f32 	%f329, %f323, %f323;
	.loc	2 161 38
	mul.f32 	%f330, %f312, %f329;
	.loc	2 161 22
	fma.rn.f32 	%f331, %f326, %f330, %f328;
	.loc	2 168 46
	mov.b32 	%r382, %f773;
	shfl.sync.bfly.b32	%r383, %r382, 16, 31, -1;
	mov.b32 	%f332, %r383;
	mov.b32 	%r384, %f781;
	shfl.sync.bfly.b32	%r385, %r384, 16, 31, -1;
	mov.b32 	%f333, %r385;
	mov.b32 	%r386, %f765;
	shfl.sync.bfly.b32	%r147, %r386, 16, 31, -1;
	mov.b32 	%f334, %r147;
	.loc	2 156 21
	sub.f32 	%f335, %f332, %f773;
	.loc	2 157 28
	add.f32 	%f336, %f765, %f334;
	.loc	2 158 39
	setp.eq.f32 	%p65, %f336, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r148, %f336;
	// begin inline asm
	div.full.f32 %r146, %r147, %r148;
	// end inline asm
	mov.b32 	%f337, %r146;
	.loc	2 158 49
	selp.f32 	%f338, 0f00000000, %f337, %p65;
	.loc	2 160 17
	fma.rn.f32 	%f339, %f335, %f338, %f773;
	.loc	2 161 15
	add.f32 	%f340, %f781, %f333;
	.loc	2 161 30
	mul.f32 	%f341, %f335, %f335;
	.loc	2 161 38
	mul.f32 	%f342, %f765, %f341;
	.loc	2 161 22
	fma.rn.f32 	%f343, %f342, %f338, %f340;
	.loc	2 168 46
	mov.b32 	%r387, %f339;
	shfl.sync.bfly.b32	%r388, %r387, 8, 31, -1;
	mov.b32 	%f344, %r388;
	mov.b32 	%r389, %f343;
	shfl.sync.bfly.b32	%r390, %r389, 8, 31, -1;
	mov.b32 	%f345, %r390;
	shfl.sync.bfly.b32	%r150, %r148, 8, 31, -1;
	mov.b32 	%f346, %r150;
	.loc	2 156 21
	sub.f32 	%f347, %f344, %f339;
	.loc	2 157 28
	add.f32 	%f348, %f336, %f346;
	.loc	2 158 39
	setp.eq.f32 	%p66, %f348, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r151, %f348;
	// begin inline asm
	div.full.f32 %r149, %r150, %r151;
	// end inline asm
	mov.b32 	%f349, %r149;
	.loc	2 158 49
	selp.f32 	%f350, 0f00000000, %f349, %p66;
	.loc	2 160 17
	fma.rn.f32 	%f351, %f347, %f350, %f339;
	.loc	2 161 15
	add.f32 	%f352, %f343, %f345;
	.loc	2 161 30
	mul.f32 	%f353, %f347, %f347;
	.loc	2 161 38
	mul.f32 	%f354, %f336, %f353;
	.loc	2 161 22
	fma.rn.f32 	%f355, %f350, %f354, %f352;
	.loc	2 168 46
	mov.b32 	%r391, %f351;
	shfl.sync.bfly.b32	%r392, %r391, 4, 31, -1;
	mov.b32 	%f356, %r392;
	mov.b32 	%r393, %f355;
	shfl.sync.bfly.b32	%r394, %r393, 4, 31, -1;
	mov.b32 	%f357, %r394;
	shfl.sync.bfly.b32	%r153, %r151, 4, 31, -1;
	mov.b32 	%f358, %r153;
	.loc	2 156 21
	sub.f32 	%f359, %f356, %f351;
	.loc	2 157 28
	add.f32 	%f360, %f348, %f358;
	.loc	2 158 39
	setp.eq.f32 	%p67, %f360, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r154, %f360;
	// begin inline asm
	div.full.f32 %r152, %r153, %r154;
	// end inline asm
	mov.b32 	%f361, %r152;
	.loc	2 158 49
	selp.f32 	%f362, 0f00000000, %f361, %p67;
	.loc	2 160 17
	fma.rn.f32 	%f363, %f359, %f362, %f351;
	.loc	2 161 15
	add.f32 	%f364, %f355, %f357;
	.loc	2 161 30
	mul.f32 	%f365, %f359, %f359;
	.loc	2 161 38
	mul.f32 	%f366, %f348, %f365;
	.loc	2 161 22
	fma.rn.f32 	%f367, %f362, %f366, %f364;
	.loc	2 168 46
	mov.b32 	%r395, %f363;
	shfl.sync.bfly.b32	%r396, %r395, 2, 31, -1;
	mov.b32 	%f368, %r396;
	mov.b32 	%r397, %f367;
	shfl.sync.bfly.b32	%r398, %r397, 2, 31, -1;
	mov.b32 	%f369, %r398;
	shfl.sync.bfly.b32	%r156, %r154, 2, 31, -1;
	mov.b32 	%f370, %r156;
	.loc	2 156 21
	sub.f32 	%f371, %f368, %f363;
	.loc	2 157 28
	add.f32 	%f372, %f360, %f370;
	.loc	2 158 39
	setp.eq.f32 	%p68, %f372, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r157, %f372;
	// begin inline asm
	div.full.f32 %r155, %r156, %r157;
	// end inline asm
	mov.b32 	%f373, %r155;
	.loc	2 158 49
	selp.f32 	%f374, 0f00000000, %f373, %p68;
	.loc	2 160 17
	fma.rn.f32 	%f375, %f371, %f374, %f363;
	.loc	2 161 15
	add.f32 	%f376, %f367, %f369;
	.loc	2 161 30
	mul.f32 	%f377, %f371, %f371;
	.loc	2 161 38
	mul.f32 	%f378, %f360, %f377;
	.loc	2 161 22
	fma.rn.f32 	%f379, %f374, %f378, %f376;
	.loc	2 168 46
	mov.b32 	%r399, %f375;
	shfl.sync.bfly.b32	%r400, %r399, 1, 31, -1;
	mov.b32 	%f380, %r400;
	mov.b32 	%r401, %f379;
	shfl.sync.bfly.b32	%r402, %r401, 1, 31, -1;
	mov.b32 	%f381, %r402;
	shfl.sync.bfly.b32	%r159, %r157, 1, 31, -1;
	mov.b32 	%f382, %r159;
	.loc	2 156 21
	sub.f32 	%f383, %f380, %f375;
	.loc	2 157 28
	add.f32 	%f384, %f372, %f382;
	.loc	2 158 39
	setp.eq.f32 	%p69, %f384, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r160, %f384;
	// begin inline asm
	div.full.f32 %r158, %r159, %r160;
	// end inline asm
	mov.b32 	%f385, %r158;
	.loc	2 158 49
	selp.f32 	%f386, 0f00000000, %f385, %p69;
	.loc	2 160 17
	fma.rn.f32 	%f387, %f383, %f386, %f375;
	.loc	2 161 15
	add.f32 	%f388, %f379, %f381;
	.loc	2 161 30
	mul.f32 	%f389, %f383, %f383;
	.loc	2 161 38
	mul.f32 	%f390, %f372, %f389;
	.loc	2 161 22
	fma.rn.f32 	%f391, %f386, %f390, %f388;
	.loc	2 168 46
	mov.b32 	%r403, %f774;
	shfl.sync.bfly.b32	%r404, %r403, 16, 31, -1;
	mov.b32 	%f392, %r404;
	mov.b32 	%r405, %f782;
	shfl.sync.bfly.b32	%r406, %r405, 16, 31, -1;
	mov.b32 	%f393, %r406;
	mov.b32 	%r407, %f766;
	shfl.sync.bfly.b32	%r162, %r407, 16, 31, -1;
	mov.b32 	%f394, %r162;
	.loc	2 156 21
	sub.f32 	%f395, %f392, %f774;
	.loc	2 157 28
	add.f32 	%f396, %f766, %f394;
	.loc	2 158 39
	setp.eq.f32 	%p70, %f396, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r163, %f396;
	// begin inline asm
	div.full.f32 %r161, %r162, %r163;
	// end inline asm
	mov.b32 	%f397, %r161;
	.loc	2 158 49
	selp.f32 	%f398, 0f00000000, %f397, %p70;
	.loc	2 160 17
	fma.rn.f32 	%f399, %f395, %f398, %f774;
	.loc	2 161 15
	add.f32 	%f400, %f782, %f393;
	.loc	2 161 30
	mul.f32 	%f401, %f395, %f395;
	.loc	2 161 38
	mul.f32 	%f402, %f766, %f401;
	.loc	2 161 22
	fma.rn.f32 	%f403, %f402, %f398, %f400;
	.loc	2 168 46
	mov.b32 	%r408, %f399;
	shfl.sync.bfly.b32	%r409, %r408, 8, 31, -1;
	mov.b32 	%f404, %r409;
	mov.b32 	%r410, %f403;
	shfl.sync.bfly.b32	%r411, %r410, 8, 31, -1;
	mov.b32 	%f405, %r411;
	shfl.sync.bfly.b32	%r165, %r163, 8, 31, -1;
	mov.b32 	%f406, %r165;
	.loc	2 156 21
	sub.f32 	%f407, %f404, %f399;
	.loc	2 157 28
	add.f32 	%f408, %f396, %f406;
	.loc	2 158 39
	setp.eq.f32 	%p71, %f408, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r166, %f408;
	// begin inline asm
	div.full.f32 %r164, %r165, %r166;
	// end inline asm
	mov.b32 	%f409, %r164;
	.loc	2 158 49
	selp.f32 	%f410, 0f00000000, %f409, %p71;
	.loc	2 160 17
	fma.rn.f32 	%f411, %f407, %f410, %f399;
	.loc	2 161 15
	add.f32 	%f412, %f403, %f405;
	.loc	2 161 30
	mul.f32 	%f413, %f407, %f407;
	.loc	2 161 38
	mul.f32 	%f414, %f396, %f413;
	.loc	2 161 22
	fma.rn.f32 	%f415, %f410, %f414, %f412;
	.loc	2 168 46
	mov.b32 	%r412, %f411;
	shfl.sync.bfly.b32	%r413, %r412, 4, 31, -1;
	mov.b32 	%f416, %r413;
	mov.b32 	%r414, %f415;
	shfl.sync.bfly.b32	%r415, %r414, 4, 31, -1;
	mov.b32 	%f417, %r415;
	shfl.sync.bfly.b32	%r168, %r166, 4, 31, -1;
	mov.b32 	%f418, %r168;
	.loc	2 156 21
	sub.f32 	%f419, %f416, %f411;
	.loc	2 157 28
	add.f32 	%f420, %f408, %f418;
	.loc	2 158 39
	setp.eq.f32 	%p72, %f420, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r169, %f420;
	// begin inline asm
	div.full.f32 %r167, %r168, %r169;
	// end inline asm
	mov.b32 	%f421, %r167;
	.loc	2 158 49
	selp.f32 	%f422, 0f00000000, %f421, %p72;
	.loc	2 160 17
	fma.rn.f32 	%f423, %f419, %f422, %f411;
	.loc	2 161 15
	add.f32 	%f424, %f415, %f417;
	.loc	2 161 30
	mul.f32 	%f425, %f419, %f419;
	.loc	2 161 38
	mul.f32 	%f426, %f408, %f425;
	.loc	2 161 22
	fma.rn.f32 	%f427, %f422, %f426, %f424;
	.loc	2 168 46
	mov.b32 	%r416, %f423;
	shfl.sync.bfly.b32	%r417, %r416, 2, 31, -1;
	mov.b32 	%f428, %r417;
	mov.b32 	%r418, %f427;
	shfl.sync.bfly.b32	%r419, %r418, 2, 31, -1;
	mov.b32 	%f429, %r419;
	shfl.sync.bfly.b32	%r171, %r169, 2, 31, -1;
	mov.b32 	%f430, %r171;
	.loc	2 156 21
	sub.f32 	%f431, %f428, %f423;
	.loc	2 157 28
	add.f32 	%f432, %f420, %f430;
	.loc	2 158 39
	setp.eq.f32 	%p73, %f432, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r172, %f432;
	// begin inline asm
	div.full.f32 %r170, %r171, %r172;
	// end inline asm
	mov.b32 	%f433, %r170;
	.loc	2 158 49
	selp.f32 	%f434, 0f00000000, %f433, %p73;
	.loc	2 160 17
	fma.rn.f32 	%f435, %f431, %f434, %f423;
	.loc	2 161 15
	add.f32 	%f436, %f427, %f429;
	.loc	2 161 30
	mul.f32 	%f437, %f431, %f431;
	.loc	2 161 38
	mul.f32 	%f438, %f420, %f437;
	.loc	2 161 22
	fma.rn.f32 	%f439, %f434, %f438, %f436;
	.loc	2 168 46
	mov.b32 	%r420, %f435;
	shfl.sync.bfly.b32	%r421, %r420, 1, 31, -1;
	mov.b32 	%f440, %r421;
	mov.b32 	%r422, %f439;
	shfl.sync.bfly.b32	%r423, %r422, 1, 31, -1;
	mov.b32 	%f441, %r423;
	shfl.sync.bfly.b32	%r174, %r172, 1, 31, -1;
	mov.b32 	%f442, %r174;
	.loc	2 156 21
	sub.f32 	%f443, %f440, %f435;
	.loc	2 157 28
	add.f32 	%f444, %f432, %f442;
	.loc	2 158 39
	setp.eq.f32 	%p74, %f444, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r175, %f444;
	// begin inline asm
	div.full.f32 %r173, %r174, %r175;
	// end inline asm
	mov.b32 	%f445, %r173;
	.loc	2 158 49
	selp.f32 	%f446, 0f00000000, %f445, %p74;
	.loc	2 160 17
	fma.rn.f32 	%f447, %f443, %f446, %f435;
	.loc	2 161 15
	add.f32 	%f448, %f439, %f441;
	.loc	2 161 30
	mul.f32 	%f449, %f443, %f443;
	.loc	2 161 38
	mul.f32 	%f450, %f432, %f449;
	.loc	2 161 22
	fma.rn.f32 	%f451, %f446, %f450, %f448;
	.loc	2 168 46
	mov.b32 	%r424, %f775;
	shfl.sync.bfly.b32	%r425, %r424, 16, 31, -1;
	mov.b32 	%f452, %r425;
	mov.b32 	%r426, %f783;
	shfl.sync.bfly.b32	%r427, %r426, 16, 31, -1;
	mov.b32 	%f453, %r427;
	mov.b32 	%r428, %f767;
	shfl.sync.bfly.b32	%r177, %r428, 16, 31, -1;
	mov.b32 	%f454, %r177;
	.loc	2 156 21
	sub.f32 	%f455, %f452, %f775;
	.loc	2 157 28
	add.f32 	%f456, %f767, %f454;
	.loc	2 158 39
	setp.eq.f32 	%p75, %f456, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r178, %f456;
	// begin inline asm
	div.full.f32 %r176, %r177, %r178;
	// end inline asm
	mov.b32 	%f457, %r176;
	.loc	2 158 49
	selp.f32 	%f458, 0f00000000, %f457, %p75;
	.loc	2 160 17
	fma.rn.f32 	%f459, %f455, %f458, %f775;
	.loc	2 161 15
	add.f32 	%f460, %f783, %f453;
	.loc	2 161 30
	mul.f32 	%f461, %f455, %f455;
	.loc	2 161 38
	mul.f32 	%f462, %f767, %f461;
	.loc	2 161 22
	fma.rn.f32 	%f463, %f462, %f458, %f460;
	.loc	2 168 46
	mov.b32 	%r429, %f459;
	shfl.sync.bfly.b32	%r430, %r429, 8, 31, -1;
	mov.b32 	%f464, %r430;
	mov.b32 	%r431, %f463;
	shfl.sync.bfly.b32	%r432, %r431, 8, 31, -1;
	mov.b32 	%f465, %r432;
	shfl.sync.bfly.b32	%r180, %r178, 8, 31, -1;
	mov.b32 	%f466, %r180;
	.loc	2 156 21
	sub.f32 	%f467, %f464, %f459;
	.loc	2 157 28
	add.f32 	%f468, %f456, %f466;
	.loc	2 158 39
	setp.eq.f32 	%p76, %f468, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r181, %f468;
	// begin inline asm
	div.full.f32 %r179, %r180, %r181;
	// end inline asm
	mov.b32 	%f469, %r179;
	.loc	2 158 49
	selp.f32 	%f470, 0f00000000, %f469, %p76;
	.loc	2 160 17
	fma.rn.f32 	%f471, %f467, %f470, %f459;
	.loc	2 161 15
	add.f32 	%f472, %f463, %f465;
	.loc	2 161 30
	mul.f32 	%f473, %f467, %f467;
	.loc	2 161 38
	mul.f32 	%f474, %f456, %f473;
	.loc	2 161 22
	fma.rn.f32 	%f475, %f470, %f474, %f472;
	.loc	2 168 46
	mov.b32 	%r433, %f471;
	shfl.sync.bfly.b32	%r434, %r433, 4, 31, -1;
	mov.b32 	%f476, %r434;
	mov.b32 	%r435, %f475;
	shfl.sync.bfly.b32	%r436, %r435, 4, 31, -1;
	mov.b32 	%f477, %r436;
	shfl.sync.bfly.b32	%r183, %r181, 4, 31, -1;
	mov.b32 	%f478, %r183;
	.loc	2 156 21
	sub.f32 	%f479, %f476, %f471;
	.loc	2 157 28
	add.f32 	%f480, %f468, %f478;
	.loc	2 158 39
	setp.eq.f32 	%p77, %f480, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r184, %f480;
	// begin inline asm
	div.full.f32 %r182, %r183, %r184;
	// end inline asm
	mov.b32 	%f481, %r182;
	.loc	2 158 49
	selp.f32 	%f482, 0f00000000, %f481, %p77;
	.loc	2 160 17
	fma.rn.f32 	%f483, %f479, %f482, %f471;
	.loc	2 161 15
	add.f32 	%f484, %f475, %f477;
	.loc	2 161 30
	mul.f32 	%f485, %f479, %f479;
	.loc	2 161 38
	mul.f32 	%f486, %f468, %f485;
	.loc	2 161 22
	fma.rn.f32 	%f487, %f482, %f486, %f484;
	.loc	2 168 46
	mov.b32 	%r437, %f483;
	shfl.sync.bfly.b32	%r438, %r437, 2, 31, -1;
	mov.b32 	%f488, %r438;
	mov.b32 	%r439, %f487;
	shfl.sync.bfly.b32	%r440, %r439, 2, 31, -1;
	mov.b32 	%f489, %r440;
	shfl.sync.bfly.b32	%r186, %r184, 2, 31, -1;
	mov.b32 	%f490, %r186;
	.loc	2 156 21
	sub.f32 	%f491, %f488, %f483;
	.loc	2 157 28
	add.f32 	%f492, %f480, %f490;
	.loc	2 158 39
	setp.eq.f32 	%p78, %f492, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r187, %f492;
	// begin inline asm
	div.full.f32 %r185, %r186, %r187;
	// end inline asm
	mov.b32 	%f493, %r185;
	.loc	2 158 49
	selp.f32 	%f494, 0f00000000, %f493, %p78;
	.loc	2 160 17
	fma.rn.f32 	%f495, %f491, %f494, %f483;
	.loc	2 161 15
	add.f32 	%f496, %f487, %f489;
	.loc	2 161 30
	mul.f32 	%f497, %f491, %f491;
	.loc	2 161 38
	mul.f32 	%f498, %f480, %f497;
	.loc	2 161 22
	fma.rn.f32 	%f499, %f494, %f498, %f496;
	.loc	2 168 46
	mov.b32 	%r441, %f495;
	shfl.sync.bfly.b32	%r442, %r441, 1, 31, -1;
	mov.b32 	%f500, %r442;
	mov.b32 	%r443, %f499;
	shfl.sync.bfly.b32	%r444, %r443, 1, 31, -1;
	mov.b32 	%f501, %r444;
	shfl.sync.bfly.b32	%r189, %r187, 1, 31, -1;
	mov.b32 	%f502, %r189;
	.loc	2 156 21
	sub.f32 	%f503, %f500, %f495;
	.loc	2 157 28
	add.f32 	%f504, %f492, %f502;
	.loc	2 158 39
	setp.eq.f32 	%p79, %f504, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r190, %f504;
	// begin inline asm
	div.full.f32 %r188, %r189, %r190;
	// end inline asm
	mov.b32 	%f505, %r188;
	.loc	2 158 49
	selp.f32 	%f506, 0f00000000, %f505, %p79;
	.loc	2 160 17
	fma.rn.f32 	%f507, %f503, %f506, %f495;
	.loc	2 161 15
	add.f32 	%f508, %f499, %f501;
	.loc	2 161 30
	mul.f32 	%f509, %f503, %f503;
	.loc	2 161 38
	mul.f32 	%f510, %f492, %f509;
	.loc	2 161 22
	fma.rn.f32 	%f511, %f506, %f510, %f508;
	.loc	2 168 46
	mov.b32 	%r445, %f776;
	shfl.sync.bfly.b32	%r446, %r445, 16, 31, -1;
	mov.b32 	%f512, %r446;
	mov.b32 	%r447, %f784;
	shfl.sync.bfly.b32	%r448, %r447, 16, 31, -1;
	mov.b32 	%f513, %r448;
	mov.b32 	%r449, %f768;
	shfl.sync.bfly.b32	%r192, %r449, 16, 31, -1;
	mov.b32 	%f514, %r192;
	.loc	2 156 21
	sub.f32 	%f515, %f512, %f776;
	.loc	2 157 28
	add.f32 	%f516, %f768, %f514;
	.loc	2 158 39
	setp.eq.f32 	%p80, %f516, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r193, %f516;
	// begin inline asm
	div.full.f32 %r191, %r192, %r193;
	// end inline asm
	mov.b32 	%f517, %r191;
	.loc	2 158 49
	selp.f32 	%f518, 0f00000000, %f517, %p80;
	.loc	2 160 17
	fma.rn.f32 	%f519, %f515, %f518, %f776;
	.loc	2 161 15
	add.f32 	%f520, %f784, %f513;
	.loc	2 161 30
	mul.f32 	%f521, %f515, %f515;
	.loc	2 161 38
	mul.f32 	%f522, %f768, %f521;
	.loc	2 161 22
	fma.rn.f32 	%f523, %f522, %f518, %f520;
	.loc	2 168 46
	mov.b32 	%r450, %f519;
	shfl.sync.bfly.b32	%r451, %r450, 8, 31, -1;
	mov.b32 	%f524, %r451;
	mov.b32 	%r452, %f523;
	shfl.sync.bfly.b32	%r453, %r452, 8, 31, -1;
	mov.b32 	%f525, %r453;
	shfl.sync.bfly.b32	%r195, %r193, 8, 31, -1;
	mov.b32 	%f526, %r195;
	.loc	2 156 21
	sub.f32 	%f527, %f524, %f519;
	.loc	2 157 28
	add.f32 	%f528, %f516, %f526;
	.loc	2 158 39
	setp.eq.f32 	%p81, %f528, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r196, %f528;
	// begin inline asm
	div.full.f32 %r194, %r195, %r196;
	// end inline asm
	mov.b32 	%f529, %r194;
	.loc	2 158 49
	selp.f32 	%f530, 0f00000000, %f529, %p81;
	.loc	2 160 17
	fma.rn.f32 	%f531, %f527, %f530, %f519;
	.loc	2 161 15
	add.f32 	%f532, %f523, %f525;
	.loc	2 161 30
	mul.f32 	%f533, %f527, %f527;
	.loc	2 161 38
	mul.f32 	%f534, %f516, %f533;
	.loc	2 161 22
	fma.rn.f32 	%f535, %f530, %f534, %f532;
	.loc	2 168 46
	mov.b32 	%r454, %f531;
	shfl.sync.bfly.b32	%r455, %r454, 4, 31, -1;
	mov.b32 	%f536, %r455;
	mov.b32 	%r456, %f535;
	shfl.sync.bfly.b32	%r457, %r456, 4, 31, -1;
	mov.b32 	%f537, %r457;
	shfl.sync.bfly.b32	%r198, %r196, 4, 31, -1;
	mov.b32 	%f538, %r198;
	.loc	2 156 21
	sub.f32 	%f539, %f536, %f531;
	.loc	2 157 28
	add.f32 	%f540, %f528, %f538;
	.loc	2 158 39
	setp.eq.f32 	%p82, %f540, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r199, %f540;
	// begin inline asm
	div.full.f32 %r197, %r198, %r199;
	// end inline asm
	mov.b32 	%f541, %r197;
	.loc	2 158 49
	selp.f32 	%f542, 0f00000000, %f541, %p82;
	.loc	2 160 17
	fma.rn.f32 	%f543, %f539, %f542, %f531;
	.loc	2 161 15
	add.f32 	%f544, %f535, %f537;
	.loc	2 161 30
	mul.f32 	%f545, %f539, %f539;
	.loc	2 161 38
	mul.f32 	%f546, %f528, %f545;
	.loc	2 161 22
	fma.rn.f32 	%f547, %f542, %f546, %f544;
	.loc	2 168 46
	mov.b32 	%r458, %f543;
	shfl.sync.bfly.b32	%r459, %r458, 2, 31, -1;
	mov.b32 	%f548, %r459;
	mov.b32 	%r460, %f547;
	shfl.sync.bfly.b32	%r461, %r460, 2, 31, -1;
	mov.b32 	%f549, %r461;
	shfl.sync.bfly.b32	%r201, %r199, 2, 31, -1;
	mov.b32 	%f550, %r201;
	.loc	2 156 21
	sub.f32 	%f551, %f548, %f543;
	.loc	2 157 28
	add.f32 	%f552, %f540, %f550;
	.loc	2 158 39
	setp.eq.f32 	%p83, %f552, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r202, %f552;
	// begin inline asm
	div.full.f32 %r200, %r201, %r202;
	// end inline asm
	mov.b32 	%f553, %r200;
	.loc	2 158 49
	selp.f32 	%f554, 0f00000000, %f553, %p83;
	.loc	2 160 17
	fma.rn.f32 	%f555, %f551, %f554, %f543;
	.loc	2 161 15
	add.f32 	%f556, %f547, %f549;
	.loc	2 161 30
	mul.f32 	%f557, %f551, %f551;
	.loc	2 161 38
	mul.f32 	%f558, %f540, %f557;
	.loc	2 161 22
	fma.rn.f32 	%f559, %f554, %f558, %f556;
	.loc	2 168 46
	mov.b32 	%r462, %f555;
	shfl.sync.bfly.b32	%r463, %r462, 1, 31, -1;
	mov.b32 	%f560, %r463;
	mov.b32 	%r464, %f559;
	shfl.sync.bfly.b32	%r465, %r464, 1, 31, -1;
	mov.b32 	%f561, %r465;
	shfl.sync.bfly.b32	%r204, %r202, 1, 31, -1;
	mov.b32 	%f562, %r204;
	.loc	2 156 21
	sub.f32 	%f563, %f560, %f555;
	.loc	2 157 28
	add.f32 	%f564, %f552, %f562;
	.loc	2 158 39
	setp.eq.f32 	%p84, %f564, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r205, %f564;
	// begin inline asm
	div.full.f32 %r203, %r204, %r205;
	// end inline asm
	mov.b32 	%f565, %r203;
	.loc	2 158 49
	selp.f32 	%f566, 0f00000000, %f565, %p84;
	.loc	2 160 17
	fma.rn.f32 	%f567, %f563, %f566, %f555;
	.loc	2 161 15
	add.f32 	%f568, %f559, %f561;
	.loc	2 161 30
	mul.f32 	%f569, %f563, %f563;
	.loc	2 161 38
	mul.f32 	%f570, %f552, %f569;
	.loc	2 161 22
	fma.rn.f32 	%f571, %f566, %f570, %f568;
	.loc	2 168 46
	mov.b32 	%r466, %f777;
	shfl.sync.bfly.b32	%r467, %r466, 16, 31, -1;
	mov.b32 	%f572, %r467;
	mov.b32 	%r468, %f785;
	shfl.sync.bfly.b32	%r469, %r468, 16, 31, -1;
	mov.b32 	%f573, %r469;
	mov.b32 	%r470, %f769;
	shfl.sync.bfly.b32	%r207, %r470, 16, 31, -1;
	mov.b32 	%f574, %r207;
	.loc	2 156 21
	sub.f32 	%f575, %f572, %f777;
	.loc	2 157 28
	add.f32 	%f576, %f769, %f574;
	.loc	2 158 39
	setp.eq.f32 	%p85, %f576, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r208, %f576;
	// begin inline asm
	div.full.f32 %r206, %r207, %r208;
	// end inline asm
	mov.b32 	%f577, %r206;
	.loc	2 158 49
	selp.f32 	%f578, 0f00000000, %f577, %p85;
	.loc	2 160 17
	fma.rn.f32 	%f579, %f575, %f578, %f777;
	.loc	2 161 15
	add.f32 	%f580, %f785, %f573;
	.loc	2 161 30
	mul.f32 	%f581, %f575, %f575;
	.loc	2 161 38
	mul.f32 	%f582, %f769, %f581;
	.loc	2 161 22
	fma.rn.f32 	%f583, %f582, %f578, %f580;
	.loc	2 168 46
	mov.b32 	%r471, %f579;
	shfl.sync.bfly.b32	%r472, %r471, 8, 31, -1;
	mov.b32 	%f584, %r472;
	mov.b32 	%r473, %f583;
	shfl.sync.bfly.b32	%r474, %r473, 8, 31, -1;
	mov.b32 	%f585, %r474;
	shfl.sync.bfly.b32	%r210, %r208, 8, 31, -1;
	mov.b32 	%f586, %r210;
	.loc	2 156 21
	sub.f32 	%f587, %f584, %f579;
	.loc	2 157 28
	add.f32 	%f588, %f576, %f586;
	.loc	2 158 39
	setp.eq.f32 	%p86, %f588, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r211, %f588;
	// begin inline asm
	div.full.f32 %r209, %r210, %r211;
	// end inline asm
	mov.b32 	%f589, %r209;
	.loc	2 158 49
	selp.f32 	%f590, 0f00000000, %f589, %p86;
	.loc	2 160 17
	fma.rn.f32 	%f591, %f587, %f590, %f579;
	.loc	2 161 15
	add.f32 	%f592, %f583, %f585;
	.loc	2 161 30
	mul.f32 	%f593, %f587, %f587;
	.loc	2 161 38
	mul.f32 	%f594, %f576, %f593;
	.loc	2 161 22
	fma.rn.f32 	%f595, %f590, %f594, %f592;
	.loc	2 168 46
	mov.b32 	%r475, %f591;
	shfl.sync.bfly.b32	%r476, %r475, 4, 31, -1;
	mov.b32 	%f596, %r476;
	mov.b32 	%r477, %f595;
	shfl.sync.bfly.b32	%r478, %r477, 4, 31, -1;
	mov.b32 	%f597, %r478;
	shfl.sync.bfly.b32	%r213, %r211, 4, 31, -1;
	mov.b32 	%f598, %r213;
	.loc	2 156 21
	sub.f32 	%f599, %f596, %f591;
	.loc	2 157 28
	add.f32 	%f600, %f588, %f598;
	.loc	2 158 39
	setp.eq.f32 	%p87, %f600, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r214, %f600;
	// begin inline asm
	div.full.f32 %r212, %r213, %r214;
	// end inline asm
	mov.b32 	%f601, %r212;
	.loc	2 158 49
	selp.f32 	%f602, 0f00000000, %f601, %p87;
	.loc	2 160 17
	fma.rn.f32 	%f603, %f599, %f602, %f591;
	.loc	2 161 15
	add.f32 	%f604, %f595, %f597;
	.loc	2 161 30
	mul.f32 	%f605, %f599, %f599;
	.loc	2 161 38
	mul.f32 	%f606, %f588, %f605;
	.loc	2 161 22
	fma.rn.f32 	%f607, %f602, %f606, %f604;
	.loc	2 168 46
	mov.b32 	%r479, %f603;
	shfl.sync.bfly.b32	%r480, %r479, 2, 31, -1;
	mov.b32 	%f608, %r480;
	mov.b32 	%r481, %f607;
	shfl.sync.bfly.b32	%r482, %r481, 2, 31, -1;
	mov.b32 	%f609, %r482;
	shfl.sync.bfly.b32	%r216, %r214, 2, 31, -1;
	mov.b32 	%f610, %r216;
	.loc	2 156 21
	sub.f32 	%f611, %f608, %f603;
	.loc	2 157 28
	add.f32 	%f612, %f600, %f610;
	.loc	2 158 39
	setp.eq.f32 	%p88, %f612, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r217, %f612;
	// begin inline asm
	div.full.f32 %r215, %r216, %r217;
	// end inline asm
	mov.b32 	%f613, %r215;
	.loc	2 158 49
	selp.f32 	%f614, 0f00000000, %f613, %p88;
	.loc	2 160 17
	fma.rn.f32 	%f615, %f611, %f614, %f603;
	.loc	2 161 15
	add.f32 	%f616, %f607, %f609;
	.loc	2 161 30
	mul.f32 	%f617, %f611, %f611;
	.loc	2 161 38
	mul.f32 	%f618, %f600, %f617;
	.loc	2 161 22
	fma.rn.f32 	%f619, %f614, %f618, %f616;
	.loc	2 168 46
	mov.b32 	%r483, %f615;
	shfl.sync.bfly.b32	%r484, %r483, 1, 31, -1;
	mov.b32 	%f620, %r484;
	mov.b32 	%r485, %f619;
	shfl.sync.bfly.b32	%r486, %r485, 1, 31, -1;
	mov.b32 	%f621, %r486;
	shfl.sync.bfly.b32	%r219, %r217, 1, 31, -1;
	mov.b32 	%f622, %r219;
	.loc	2 156 21
	sub.f32 	%f623, %f620, %f615;
	.loc	2 157 28
	add.f32 	%f624, %f612, %f622;
	.loc	2 158 39
	setp.eq.f32 	%p89, %f624, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r220, %f624;
	// begin inline asm
	div.full.f32 %r218, %r219, %r220;
	// end inline asm
	mov.b32 	%f625, %r218;
	.loc	2 158 49
	selp.f32 	%f626, 0f00000000, %f625, %p89;
	.loc	2 160 17
	fma.rn.f32 	%f627, %f623, %f626, %f615;
	.loc	2 161 15
	add.f32 	%f628, %f619, %f621;
	.loc	2 161 30
	mul.f32 	%f629, %f623, %f623;
	.loc	2 161 38
	mul.f32 	%f630, %f612, %f629;
	.loc	2 161 22
	fma.rn.f32 	%f631, %f626, %f630, %f628;
	.loc	2 168 46
	setp.eq.s32 	%p20, %r318, 0;
	shr.u32 	%r487, %r1, 3;
	and.b32  	%r488, %r487, 60;
	add.s32 	%r221, %r17, %r488;
	mov.b32 	%r222, %f207;
	// begin inline asm
	@%p20 st.shared.b32 [ %r221 + 0 ], %r222;
	// end inline asm
	add.s32 	%r490, %r17, 512;
	add.s32 	%r223, %r490, %r488;
	mov.b32 	%r224, %f211;
	// begin inline asm
	@%p20 st.shared.b32 [ %r223 + 0 ], %r224;
	// end inline asm
	add.s32 	%r491, %r17, 1024;
	add.s32 	%r225, %r491, %r488;
	// begin inline asm
	@%p20 st.shared.b32 [ %r225 + 0 ], %r115;
	// end inline asm
	add.s32 	%r227, %r221, 64;
	mov.b32 	%r228, %f267;
	// begin inline asm
	@%p20 st.shared.b32 [ %r227 + 0 ], %r228;
	// end inline asm
	add.s32 	%r229, %r223, 64;
	mov.b32 	%r230, %f271;
	// begin inline asm
	@%p20 st.shared.b32 [ %r229 + 0 ], %r230;
	// end inline asm
	add.s32 	%r231, %r225, 64;
	// begin inline asm
	@%p20 st.shared.b32 [ %r231 + 0 ], %r130;
	// end inline asm
	add.s32 	%r233, %r221, 128;
	mov.b32 	%r234, %f327;
	// begin inline asm
	@%p20 st.shared.b32 [ %r233 + 0 ], %r234;
	// end inline asm
	add.s32 	%r235, %r223, 128;
	mov.b32 	%r236, %f331;
	// begin inline asm
	@%p20 st.shared.b32 [ %r235 + 0 ], %r236;
	// end inline asm
	add.s32 	%r237, %r225, 128;
	// begin inline asm
	@%p20 st.shared.b32 [ %r237 + 0 ], %r145;
	// end inline asm
	add.s32 	%r239, %r221, 192;
	mov.b32 	%r240, %f387;
	// begin inline asm
	@%p20 st.shared.b32 [ %r239 + 0 ], %r240;
	// end inline asm
	add.s32 	%r241, %r223, 192;
	mov.b32 	%r242, %f391;
	// begin inline asm
	@%p20 st.shared.b32 [ %r241 + 0 ], %r242;
	// end inline asm
	add.s32 	%r243, %r225, 192;
	// begin inline asm
	@%p20 st.shared.b32 [ %r243 + 0 ], %r160;
	// end inline asm
	add.s32 	%r245, %r221, 256;
	mov.b32 	%r246, %f447;
	// begin inline asm
	@%p20 st.shared.b32 [ %r245 + 0 ], %r246;
	// end inline asm
	add.s32 	%r247, %r223, 256;
	mov.b32 	%r248, %f451;
	// begin inline asm
	@%p20 st.shared.b32 [ %r247 + 0 ], %r248;
	// end inline asm
	add.s32 	%r249, %r225, 256;
	// begin inline asm
	@%p20 st.shared.b32 [ %r249 + 0 ], %r175;
	// end inline asm
	add.s32 	%r251, %r221, 320;
	mov.b32 	%r252, %f507;
	// begin inline asm
	@%p20 st.shared.b32 [ %r251 + 0 ], %r252;
	// end inline asm
	add.s32 	%r253, %r223, 320;
	mov.b32 	%r254, %f511;
	// begin inline asm
	@%p20 st.shared.b32 [ %r253 + 0 ], %r254;
	// end inline asm
	add.s32 	%r255, %r225, 320;
	// begin inline asm
	@%p20 st.shared.b32 [ %r255 + 0 ], %r190;
	// end inline asm
	add.s32 	%r257, %r221, 384;
	mov.b32 	%r258, %f567;
	// begin inline asm
	@%p20 st.shared.b32 [ %r257 + 0 ], %r258;
	// end inline asm
	add.s32 	%r259, %r223, 384;
	mov.b32 	%r260, %f571;
	// begin inline asm
	@%p20 st.shared.b32 [ %r259 + 0 ], %r260;
	// end inline asm
	add.s32 	%r261, %r225, 384;
	// begin inline asm
	@%p20 st.shared.b32 [ %r261 + 0 ], %r205;
	// end inline asm
	add.s32 	%r263, %r221, 448;
	mov.b32 	%r264, %f627;
	// begin inline asm
	@%p20 st.shared.b32 [ %r263 + 0 ], %r264;
	// end inline asm
	add.s32 	%r265, %r223, 448;
	mov.b32 	%r266, %f631;
	// begin inline asm
	@%p20 st.shared.b32 [ %r265 + 0 ], %r266;
	// end inline asm
	add.s32 	%r267, %r225, 448;
	// begin inline asm
	@%p20 st.shared.b32 [ %r267 + 0 ], %r220;
	// end inline asm
	bar.sync 	0;
	setp.lt.s32 	%p44, %r1, 128;
	shl.b32 	%r492, %r1, 2;
	add.s32 	%r270, %r17, %r492;
	// begin inline asm
	@%p44 ld.shared.b32 %r269, [ %r270 + 0 ];
	// end inline asm
	mov.b32 	%f632, %r269;
	add.s32 	%r272, %r490, %r492;
	// begin inline asm
	@%p44 ld.shared.b32 %r271, [ %r272 + 0 ];
	// end inline asm
	mov.b32 	%f633, %r271;
	add.s32 	%r274, %r491, %r492;
	// begin inline asm
	@%p44 ld.shared.b32 %r273, [ %r274 + 0 ];
	// end inline asm
	mov.b32 	%f634, %r273;
	shfl.sync.bfly.b32	%r493, %r269, 8, 31, -1;
	mov.b32 	%f635, %r493;
	shfl.sync.bfly.b32	%r494, %r271, 8, 31, -1;
	mov.b32 	%f636, %r494;
	shfl.sync.bfly.b32	%r276, %r273, 8, 31, -1;
	mov.b32 	%f637, %r276;
	.loc	2 156 21
	sub.f32 	%f638, %f635, %f632;
	.loc	2 157 28
	add.f32 	%f639, %f634, %f637;
	.loc	2 158 39
	setp.eq.f32 	%p90, %f639, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r277, %f639;
	// begin inline asm
	div.full.f32 %r275, %r276, %r277;
	// end inline asm
	mov.b32 	%f640, %r275;
	.loc	2 158 49
	selp.f32 	%f641, 0f00000000, %f640, %p90;
	.loc	2 160 17
	fma.rn.f32 	%f642, %f638, %f641, %f632;
	.loc	2 161 15
	add.f32 	%f643, %f633, %f636;
	.loc	2 161 30
	mul.f32 	%f644, %f638, %f638;
	.loc	2 161 38
	mul.f32 	%f645, %f634, %f644;
	.loc	2 161 22
	fma.rn.f32 	%f646, %f645, %f641, %f643;
	.loc	2 168 46
	mov.b32 	%r495, %f642;
	shfl.sync.bfly.b32	%r496, %r495, 4, 31, -1;
	mov.b32 	%f647, %r496;
	mov.b32 	%r497, %f646;
	shfl.sync.bfly.b32	%r498, %r497, 4, 31, -1;
	mov.b32 	%f648, %r498;
	shfl.sync.bfly.b32	%r279, %r277, 4, 31, -1;
	mov.b32 	%f649, %r279;
	.loc	2 156 21
	sub.f32 	%f650, %f647, %f642;
	.loc	2 157 28
	add.f32 	%f651, %f639, %f649;
	.loc	2 158 39
	setp.eq.f32 	%p91, %f651, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r280, %f651;
	// begin inline asm
	div.full.f32 %r278, %r279, %r280;
	// end inline asm
	mov.b32 	%f652, %r278;
	.loc	2 158 49
	selp.f32 	%f653, 0f00000000, %f652, %p91;
	.loc	2 160 17
	fma.rn.f32 	%f654, %f650, %f653, %f642;
	.loc	2 161 15
	add.f32 	%f655, %f646, %f648;
	.loc	2 161 30
	mul.f32 	%f656, %f650, %f650;
	.loc	2 161 38
	mul.f32 	%f657, %f639, %f656;
	.loc	2 161 22
	fma.rn.f32 	%f658, %f653, %f657, %f655;
	.loc	2 168 46
	mov.b32 	%r499, %f654;
	shfl.sync.bfly.b32	%r500, %r499, 2, 31, -1;
	mov.b32 	%f659, %r500;
	mov.b32 	%r501, %f658;
	shfl.sync.bfly.b32	%r502, %r501, 2, 31, -1;
	mov.b32 	%f660, %r502;
	shfl.sync.bfly.b32	%r282, %r280, 2, 31, -1;
	mov.b32 	%f661, %r282;
	.loc	2 156 21
	sub.f32 	%f662, %f659, %f654;
	.loc	2 157 28
	add.f32 	%f663, %f651, %f661;
	.loc	2 158 39
	setp.eq.f32 	%p92, %f663, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r283, %f663;
	// begin inline asm
	div.full.f32 %r281, %r282, %r283;
	// end inline asm
	mov.b32 	%f664, %r281;
	.loc	2 158 49
	selp.f32 	%f665, 0f00000000, %f664, %p92;
	.loc	2 160 17
	fma.rn.f32 	%f666, %f662, %f665, %f654;
	.loc	2 161 15
	add.f32 	%f667, %f658, %f660;
	.loc	2 161 30
	mul.f32 	%f668, %f662, %f662;
	.loc	2 161 38
	mul.f32 	%f669, %f651, %f668;
	.loc	2 161 22
	fma.rn.f32 	%f670, %f665, %f669, %f667;
	.loc	2 168 46
	mov.b32 	%r503, %f666;
	shfl.sync.bfly.b32	%r504, %r503, 1, 31, -1;
	mov.b32 	%f671, %r504;
	mov.b32 	%r505, %f670;
	shfl.sync.bfly.b32	%r506, %r505, 1, 31, -1;
	mov.b32 	%f672, %r506;
	shfl.sync.bfly.b32	%r285, %r283, 1, 31, -1;
	mov.b32 	%f673, %r285;
	.loc	2 156 21
	sub.f32 	%f674, %f671, %f666;
	.loc	2 157 28
	add.f32 	%f675, %f663, %f673;
	.loc	2 158 39
	setp.eq.f32 	%p93, %f675, 0f00000000;
	.loc	2 158 60
	mov.b32 	%r286, %f675;
	// begin inline asm
	div.full.f32 %r284, %r285, %r286;
	// end inline asm
	mov.b32 	%f676, %r284;
	.loc	2 158 49
	selp.f32 	%f677, 0f00000000, %f676, %p93;
	.loc	2 160 17
	fma.rn.f32 	%f678, %f674, %f677, %f666;
	.loc	2 161 15
	add.f32 	%f679, %f670, %f672;
	.loc	2 161 30
	mul.f32 	%f680, %f674, %f674;
	.loc	2 161 38
	mul.f32 	%f681, %f663, %f680;
	.loc	2 161 22
	fma.rn.f32 	%f682, %f677, %f681, %f679;
	.loc	2 168 46
	and.b32  	%r507, %r1, 15;
	setp.eq.s32 	%p94, %r507, 0;
	and.pred  	%p47, %p44, %p94;
	mov.b32 	%r288, %f678;
	// begin inline asm
	@%p47 st.shared.b32 [ %r270 + 0 ], %r288;
	// end inline asm
	mov.b32 	%r290, %f682;
	// begin inline asm
	@%p47 st.shared.b32 [ %r272 + 0 ], %r290;
	// end inline asm
	// begin inline asm
	@%p47 st.shared.b32 [ %r274 + 0 ], %r286;
	// end inline asm
	bar.sync 	0;
	ld.shared.f32 	%f81, [global_smem];
	ld.shared.f32 	%f82, [global_smem+64];
	ld.shared.f32 	%f83, [global_smem+128];
	ld.shared.f32 	%f84, [global_smem+192];
	ld.shared.f32 	%f85, [global_smem+256];
	ld.shared.f32 	%f86, [global_smem+320];
	ld.shared.f32 	%f87, [global_smem+384];
	ld.shared.f32 	%f88, [global_smem+448];
$L__tmp4:
	.loc	1 69 24
	ld.shared.u32 	%r294, [global_smem+512];
	mov.b32 	%r295, 1161822208;
	// begin inline asm
	div.full.f32 %r293, %r294, %r295;
	// end inline asm
	mov.b32 	%f683, %r293;
	ld.shared.u32 	%r297, [global_smem+576];
	// begin inline asm
	div.full.f32 %r296, %r297, %r295;
	// end inline asm
	mov.b32 	%f684, %r296;
	ld.shared.u32 	%r300, [global_smem+640];
	// begin inline asm
	div.full.f32 %r299, %r300, %r295;
	// end inline asm
	mov.b32 	%f685, %r299;
	ld.shared.u32 	%r303, [global_smem+704];
	// begin inline asm
	div.full.f32 %r302, %r303, %r295;
	// end inline asm
	mov.b32 	%f686, %r302;
	ld.shared.u32 	%r306, [global_smem+768];
	// begin inline asm
	div.full.f32 %r305, %r306, %r295;
	// end inline asm
	mov.b32 	%f687, %r305;
	ld.shared.u32 	%r309, [global_smem+832];
	// begin inline asm
	div.full.f32 %r308, %r309, %r295;
	// end inline asm
	mov.b32 	%f688, %r308;
	ld.shared.u32 	%r312, [global_smem+896];
	// begin inline asm
	div.full.f32 %r311, %r312, %r295;
	// end inline asm
	mov.b32 	%f689, %r311;
	ld.shared.u32 	%r315, [global_smem+960];
	// begin inline asm
	div.full.f32 %r314, %r315, %r295;
	// end inline asm
	mov.b32 	%f690, %r314;
	.loc	1 71 24
	add.f32 	%f89, %f683, 0f358637BD;
	add.f32 	%f90, %f684, 0f358637BD;
	add.f32 	%f91, %f685, 0f358637BD;
	add.f32 	%f92, %f686, 0f358637BD;
	add.f32 	%f93, %f687, 0f358637BD;
	add.f32 	%f94, %f688, 0f358637BD;
	add.f32 	%f95, %f689, 0f358637BD;
	add.f32 	%f96, %f690, 0f358637BD;
	.loc	1 57 36
	add.s64 	%rd32, %rd1, 18432;
	add.s64 	%rd44, %rd21, %rd32;
	add.s64 	%rd43, %rd20, %rd32;
	mov.b32 	%r546, -512;
	rsqrt.approx.ftz.f32 	%f711, %f89;
	rsqrt.approx.ftz.f32 	%f712, %f90;
	rsqrt.approx.ftz.f32 	%f713, %f91;
	rsqrt.approx.ftz.f32 	%f714, %f92;
	rsqrt.approx.ftz.f32 	%f715, %f93;
	rsqrt.approx.ftz.f32 	%f716, %f94;
	rsqrt.approx.ftz.f32 	%f717, %f95;
	rsqrt.approx.ftz.f32 	%f718, %f96;
$L__BB0_5:
	add.s32 	%r546, %r546, 512;
	.loc	1 61 39
	add.s32 	%r540, %r546, %r4;
	mul.wide.s32 	%rd39, %r540, 2;
	add.s64 	%rd33, %rd18, %rd39;
	mov.b32 	%r512, 0;
	.loc	1 61 56
	// begin inline asm
	mov.u32 %r508, 0x0;
	mov.u32 %r509, 0x0;
	mov.u32 %r510, 0x0;
	mov.u32 %r511, 0x0;
	@%p1 ld.global.L1::evict_first.v4.b32 { %r508, %r509, %r510, %r511 }, [ %rd33 + 0 ];
	@!%p1 mov.u32 %r508, %r512;
	@!%p1 mov.u32 %r509, %r512;
	@!%p1 mov.u32 %r510, %r512;
	@!%p1 mov.u32 %r511, %r512;
	// end inline asm
	.loc	1 73 24
	bar.sync 	0;
	st.shared.v4.b32 	[%r2], {%r508, %r509, %r510, %r511};
	bar.sync 	0;
	ld.shared.u16 	%rs34, [%r3];
	ld.shared.u16 	%rs35, [%r3+1040];
	ld.shared.u16 	%rs36, [%r3+2080];
	ld.shared.u16 	%rs37, [%r3+3120];
	ld.shared.u16 	%rs38, [%r3+4160];
	ld.shared.u16 	%rs39, [%r3+5200];
	ld.shared.u16 	%rs40, [%r3+6240];
	ld.shared.u16 	%rs41, [%r3+7280];
	.loc	1 61 108
	// begin inline asm
	cvt.f32.bf16 %r516, %rs34;
	// end inline asm
	mov.b32 	%f691, %r516;
	// begin inline asm
	cvt.f32.bf16 %r517, %rs35;
	// end inline asm
	mov.b32 	%f692, %r517;
	// begin inline asm
	cvt.f32.bf16 %r518, %rs36;
	// end inline asm
	mov.b32 	%f693, %r518;
	// begin inline asm
	cvt.f32.bf16 %r519, %rs37;
	// end inline asm
	mov.b32 	%f694, %r519;
	// begin inline asm
	cvt.f32.bf16 %r520, %rs38;
	// end inline asm
	mov.b32 	%f695, %r520;
	// begin inline asm
	cvt.f32.bf16 %r521, %rs39;
	// end inline asm
	mov.b32 	%f696, %r521;
	// begin inline asm
	cvt.f32.bf16 %r522, %rs40;
	// end inline asm
	mov.b32 	%f697, %r522;
	// begin inline asm
	cvt.f32.bf16 %r523, %rs41;
	// end inline asm
	mov.b32 	%f698, %r523;
	.loc	1 62 48
	add.s64 	%rd34, %rd43, 6144;
	// begin inline asm
	mov.u16 %rs42, 0x0;
	@%p1 ld.global.L1::evict_last.b16 { %rs42 }, [ %rd34 + 0 ];
	@!%p1 mov.u16 %rs42, %rs10;
	// end inline asm
	.loc	1 62 99
	// begin inline asm
	cvt.f32.bf16 %r524, %rs42;
	// end inline asm
	mov.b32 	%f699, %r524;
	.loc	1 63 48
	add.s64 	%rd35, %rd44, 6144;
	// begin inline asm
	mov.u16 %rs45, 0x0;
	@%p1 ld.global.L1::evict_last.b16 { %rs45 }, [ %rd35 + 0 ];
	@!%p1 mov.u16 %rs45, %rs10;
	// end inline asm
	.loc	1 63 99
	// begin inline asm
	cvt.f32.bf16 %r525, %rs45;
	// end inline asm
	mov.b32 	%f700, %r525;
	.loc	1 64 47
	// begin inline asm
	mov.u16 %rs48, 0x0;
	@%p1 ld.global.L1::evict_last.b16 { %rs48 }, [ %rd43 + 0 ];
	@!%p1 mov.u16 %rs48, %rs10;
	// end inline asm
	.loc	1 64 98
	// begin inline asm
	cvt.f32.bf16 %r526, %rs48;
	// end inline asm
	mov.b32 	%f701, %r526;
	.loc	1 65 47
	// begin inline asm
	mov.u16 %rs51, 0x0;
	@%p1 ld.global.L1::evict_last.b16 { %rs51 }, [ %rd44 + 0 ];
	@!%p1 mov.u16 %rs51, %rs10;
	// end inline asm
	.loc	1 65 98
	// begin inline asm
	cvt.f32.bf16 %r527, %rs51;
	// end inline asm
	mov.b32 	%f702, %r527;
	.loc	1 67 24
	sub.f32 	%f703, %f691, %f81;
	sub.f32 	%f704, %f692, %f82;
	sub.f32 	%f705, %f693, %f83;
	sub.f32 	%f706, %f694, %f84;
	sub.f32 	%f707, %f695, %f85;
	sub.f32 	%f708, %f696, %f86;
	sub.f32 	%f709, %f697, %f87;
	sub.f32 	%f710, %f698, %f88;
	.loc	1 73 24
	mul.f32 	%f719, %f703, %f711;
	mul.f32 	%f720, %f704, %f712;
	mul.f32 	%f721, %f705, %f713;
	mul.f32 	%f722, %f706, %f714;
	mul.f32 	%f723, %f707, %f715;
	mul.f32 	%f724, %f708, %f716;
	mul.f32 	%f725, %f709, %f717;
	mul.f32 	%f726, %f710, %f718;
	.loc	1 75 24
	add.f32 	%f727, %f699, %f700;
	.loc	1 77 24
	add.f32 	%f728, %f727, 0f3F800000;
	.loc	1 79 24
	add.f32 	%f729, %f701, %f702;
	.loc	1 80 24
	fma.rn.f32 	%f730, %f728, %f719, %f729;
	fma.rn.f32 	%f731, %f728, %f720, %f729;
	fma.rn.f32 	%f732, %f728, %f721, %f729;
	fma.rn.f32 	%f733, %f728, %f722, %f729;
	fma.rn.f32 	%f734, %f728, %f723, %f729;
	fma.rn.f32 	%f735, %f728, %f724, %f729;
	fma.rn.f32 	%f736, %f728, %f725, %f729;
	fma.rn.f32 	%f737, %f728, %f726, %f729;
	.loc	1 81 29
	add.s64 	%rd38, %rd22, %rd39;
	.loc	1 81 53
	mov.b32 	%r528, %f730;
	// begin inline asm
	cvt.rn.bf16.f32 %rs54, %r528;
	// end inline asm
	mov.b32 	%r529, %f731;
	// begin inline asm
	cvt.rn.bf16.f32 %rs55, %r529;
	// end inline asm
	mov.b32 	%r530, %f732;
	// begin inline asm
	cvt.rn.bf16.f32 %rs56, %r530;
	// end inline asm
	mov.b32 	%r531, %f733;
	// begin inline asm
	cvt.rn.bf16.f32 %rs57, %r531;
	// end inline asm
	mov.b32 	%r532, %f734;
	// begin inline asm
	cvt.rn.bf16.f32 %rs58, %r532;
	// end inline asm
	mov.b32 	%r533, %f735;
	// begin inline asm
	cvt.rn.bf16.f32 %rs59, %r533;
	// end inline asm
	mov.b32 	%r534, %f736;
	// begin inline asm
	cvt.rn.bf16.f32 %rs60, %r534;
	// end inline asm
	mov.b32 	%r535, %f737;
	// begin inline asm
	cvt.rn.bf16.f32 %rs61, %r535;
	// end inline asm
	bar.sync 	0;
	st.shared.u16 	[%r3], %rs54;
	st.shared.u16 	[%r3+1040], %rs55;
	st.shared.u16 	[%r3+2080], %rs56;
	st.shared.u16 	[%r3+3120], %rs57;
	st.shared.u16 	[%r3+4160], %rs58;
	st.shared.u16 	[%r3+5200], %rs59;
	st.shared.u16 	[%r3+6240], %rs60;
	st.shared.u16 	[%r3+7280], %rs61;
	bar.sync 	0;
	ld.shared.v4.u32 	{%r536, %r537, %r538, %r539}, [%r2];
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd38 + 0 ], { %r536, %r537, %r538, %r539 };
	// end inline asm
	.loc	1 57 36
	add.s64 	%rd44, %rd44, 1024;
	add.s64 	%rd43, %rd43, 1024;
	setp.lt.u32 	%p109, %r546, 2560;
	@%p109 bra 	$L__BB0_5;
	.loc	1 57 4
	ret;
$L__tmp5:
$L__func_end0:

}
	.file	1 "/opt/inductor_cache/5d/c5doacgkcjmadaew4nigdhhawppehsccl55ieseqw5r5objqfxpm.py"
	.file	2 "/usr/local/lib/python3.10/site-packages/torch/_inductor/runtime/triton_helpers.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 11
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 197
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 53
.b8 100
.b8 111
.b8 97
.b8 99
.b8 103
.b8 107
.b8 99
.b8 106
.b8 109
.b8 97
.b8 100
.b8 97
.b8 101
.b8 119
.b8 52
.b8 110
.b8 105
.b8 103
.b8 100
.b8 104
.b8 104
.b8 97
.b8 119
.b8 112
.b8 112
.b8 101
.b8 104
.b8 115
.b8 99
.b8 99
.b8 108
.b8 53
.b8 53
.b8 105
.b8 101
.b8 115
.b8 101
.b8 113
.b8 119
.b8 53
.b8 114
.b8 53
.b8 111
.b8 98
.b8 106
.b8 113
.b8 102
.b8 120
.b8 112
.b8 109
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 111
.b8 112
.b8 116
.b8 47
.b8 105
.b8 110
.b8 100
.b8 117
.b8 99
.b8 116
.b8 111
.b8 114
.b8 95
.b8 99
.b8 97
.b8 99
.b8 104
.b8 101
.b8 47
.b8 53
.b8 100
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 95
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 120
.b8 4
.b32 120
.b64 $L__tmp1
.b64 $L__tmp2
.b8 1
.b8 45
.b8 55
.b8 4
.b32 120
.b64 $L__tmp3
.b64 $L__tmp4
.b8 1
.b8 52
.b8 44
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}
